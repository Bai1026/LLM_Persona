#!/usr/bin/env python3
"""
ç´”ç²¹çš„ chat_log è§£æè…³æœ¬
å¾ chat_log æª”æ¡ˆä¸­æå– uses è³‡æ–™
"""

import json
import re
import argparse
import os

def clean_repetitive_content(text):
    """æ¸…ç†é‡è¤‡çš„å…§å®¹"""
    if not text:
        return text
    
    # é¦–å…ˆè™•ç†ç‰¹æ®Šçš„é‡è¤‡æ¨¡å¼ï¼šã€ŒEach of these bowls, now, a bowl of the impossible...ã€
    impossible_pattern = r'Each of these bowls, now, a bowl of the impossible.*'
    match = re.search(impossible_pattern, text, re.DOTALL | re.IGNORECASE)
    if match:
        text = text[:match.start()].strip()
    
    # æª¢æ¸¬ä¸¦ç§»é™¤æ˜é¡¯çš„é‡è¤‡æ¨¡å¼
    # ä¾‹å¦‚ï¼šã€Œa bowl of the impossible, a bowl of the impossible, ...ã€
    
    # æ‰¾å‡ºé‡è¤‡çš„çŸ­èªæ¨¡å¼
    # å…ˆåˆ†å‰²æˆå¥å­æˆ–çŸ­èª
    phrases = re.split(r'[,ï¼Œã€‚ï¼!?ï¼Ÿ]', text)
    
    # å¦‚æœæœ‰å¾ˆå¤šé‡è¤‡çš„çŸ­èªï¼Œæˆªå–åˆ°ç¬¬ä¸€æ¬¡é‡è¤‡å‡ºç¾çš„åœ°æ–¹
    seen_phrases = set()
    clean_phrases = []
    repetition_threshold = 3  # å¦‚æœåŒä¸€å€‹çŸ­èªå‡ºç¾è¶…é3æ¬¡ï¼Œå°±æˆªæ–·
    phrase_counts = {}
    
    for phrase in phrases:
        phrase = phrase.strip()
        if not phrase:
            continue
            
        # è¨ˆç®—é€™å€‹çŸ­èªå‡ºç¾çš„æ¬¡æ•¸
        phrase_counts[phrase] = phrase_counts.get(phrase, 0) + 1
        
        # å¦‚æœé€™å€‹çŸ­èªå·²ç¶“å‡ºç¾å¤ªå¤šæ¬¡ï¼Œåœæ­¢æ·»åŠ 
        if phrase_counts[phrase] <= repetition_threshold:
            clean_phrases.append(phrase)
        else:
            # ç™¼ç¾é‡è¤‡ï¼Œåœæ­¢è™•ç†å¾ŒçºŒå…§å®¹
            break
    
    # é‡æ–°çµ„åˆæ–‡æœ¬
    cleaned = ', '.join(clean_phrases)
    
    # ç§»é™¤æ˜é¡¯çš„é‡è¤‡æ¨¡å¼ï¼ˆæ›´ç²¾ç¢ºçš„æ–¹æ³•ï¼‰
    # æª¢æ¸¬é€£çºŒé‡è¤‡çš„å–®è©æˆ–çŸ­èª
    words = cleaned.split()
    if len(words) > 20:  # åªè™•ç†è¼ƒé•·çš„æ–‡æœ¬
        # æª¢æŸ¥æœ€å¾Œéƒ¨åˆ†æ˜¯å¦æœ‰é‡è¤‡
        last_part = ' '.join(words[-20:])  # æª¢æŸ¥æœ€å¾Œ20å€‹å–®è©
        # å¦‚æœç™¼ç¾é‡è¤‡æ¨¡å¼ï¼Œæˆªå–åˆ°é‡è¤‡é–‹å§‹çš„åœ°æ–¹
        for i in range(1, 10):  # æª¢æŸ¥1-9å€‹å–®è©çš„é‡è¤‡æ¨¡å¼
            pattern = ' '.join(words[-i:])
            count = last_part.count(pattern)
            if count >= 3 and len(pattern.split()) >= 2:  # è‡³å°‘2å€‹å–®è©é‡è¤‡3æ¬¡ä»¥ä¸Š
                # æ‰¾åˆ°é‡è¤‡é–‹å§‹çš„ä½ç½®
                before_repetition = cleaned.split(pattern)[0]
                if before_repetition:
                    cleaned = before_repetition.rstrip(' ,ï¼Œ')
                break
    
    return cleaned

def extract_responses(content):
    """æå–å›æ‡‰å…§å®¹ï¼Œå¾ assistant çš„å›ç­”ä¸­è§£æå‡ºå…·é«”çš„ uses"""
    import re
    
    # é¦–å…ˆå˜—è©¦æå–å®Œæ•´çš„å›æ‡‰ï¼ŒåŒ…æ‹¬è¢« user ä¸­æ–·å¾Œçš„å…§å®¹
    enhanced_content = content
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ \nuser\n ä¸­æ–·
    user_match = re.search(r'\nuser\n', content)
    if user_match:
        # ç²å–è¢«æˆªæ–·å‰çš„å…§å®¹
        before_user = content[:user_match.start()]
        after_user_section = content[user_match.end():]
        
        # è·³éç”¨æˆ¶çš„è¼¸å…¥ï¼Œæ‰¾åˆ°å¾ŒçºŒçš„å›æ‡‰
        lines_after_user = after_user_section.split('\n')
        assistant_response_lines = []
        skip_user_input = True
        
        for line in lines_after_user:
            line = line.strip()
            # è·³éç”¨æˆ¶çš„æŒ‡ä»¤éƒ¨åˆ†
            if skip_user_input:
                if line.startswith(('Continue', 'Now', 'Imagine', 'Tell me', 'What', 'How')):
                    continue
                elif line == '' or len(line) < 10:
                    continue
                else:
                    skip_user_input = False
            
            # æ”¶é›†åŠ©ç†çš„å›æ‡‰
            if not skip_user_input and line:
                assistant_response_lines.append(line)
        
        # å¦‚æœæ‰¾åˆ°å¾ŒçºŒçš„åŠ©ç†å›æ‡‰ï¼Œå°‡å…¶åˆä½µ
        if assistant_response_lines:
            additional_response = ' '.join(assistant_response_lines)
            # æª¢æŸ¥ before_user æ˜¯å¦ä»¥ä¸å®Œæ•´çš„å¥å­çµå°¾
            if before_user.rstrip().endswith(('like', '(', 'such as', 'including', 'with')):
                # å˜—è©¦æ™ºæ…§åœ°é€£æ¥å…§å®¹
                enhanced_content = before_user.rstrip() + ' ' + additional_response
            else:
                enhanced_content = before_user
        else:
            enhanced_content = before_user
    
    # ç§»é™¤å…¶ä»–å¯èƒ½çš„æˆªæ–·æ¨™è¨˜
    cleanup_patterns = [
        r'\nContinue.*',
        r'\nNow.*',
        r'\nImagine.*'
    ]
    
    for pattern in cleanup_patterns:
        match = re.search(pattern, enhanced_content, re.DOTALL | re.IGNORECASE)
        if match:
            enhanced_content = enhanced_content[:match.start()]
    
    content = enhanced_content
    
    # å„ªåŒ–çš„æ­£è¦è¡¨é”å¼ï¼Œèƒ½è™•ç†å¤šç¨®æ ¼å¼
    patterns = [
        # æ ¼å¼1: 1. **Title** (å¯é¸å†’è™Ÿ) - æ”¹é€²ç‰ˆæœ¬ï¼Œèƒ½è™•ç†æ··åˆæ ¼å¼
        r'(\d+)\.\s*\*\*([^*]+?)\*\*:?\s*\n?(.*?)(?=\d+\.\s*\*\*|$)',
        # æ ¼å¼2: **1.** **Title** (æ–°æ ¼å¼)
        r'\*\*(\d+)\.\*\*\s*\*\*([^*]+?)\*\*\s*(.*?)(?=\*\*\d+\.\*\*|$)',
        # æ ¼å¼3: **1. Title:** (å…§å®¹)
        r'\*\*(\d+)\.\s*([^*]+?)\*\*:?\s*(.*?)(?=\*\*\d+\.|$)',
        # æ ¼å¼4: 1. **Title:** (å…§å®¹)  
        r'(\d+)\.\s*\*\*([^*]+?)\*\*:?\s*(.*?)(?=\d+\.\s*\*\*|$)',
        # æ ¼å¼5: æ•¸å­—é–‹é ­çš„ä¸€èˆ¬é …ç›®
        r'(\d+)\.\s*([^\n]*?)\n(.*?)(?=\d+\.|$)'
    ]
    
    responses = []
    
    for i, pattern in enumerate(patterns):
        matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
        print(f"DEBUG: Pattern {i+1} found {len(matches)} matches")  # é™¤éŒ¯è³‡è¨Š
        if matches:
            for j, match in enumerate(matches):
                if len(match) == 3:  # (number, title, content)
                    number = match[0].strip()
                    title = match[1].strip()
                    body = match[2].strip()
                    
                    print(f"DEBUG: Processing match {j+1}: '{title}', body length: {len(body)}")
                    
                    # æ¸…ç†é‡è¤‡çš„å…§å®¹
                    original_body_length = len(body)
                    body = clean_repetitive_content(body)
                    cleaned_body_length = len(body)
                    
                    print(f"DEBUG: Body length after cleaning: {original_body_length} -> {cleaned_body_length}")
                    
                    # å»ºæ§‹å®Œæ•´é …ç›®
                    full_item = f"**{title}**"
                    if body:
                        full_item += f": {body}"
                    responses.append(full_item)
                    print(f"DEBUG: Added response: {title}")  # é™¤éŒ¯è³‡è¨Š
            
            if responses:  # å¦‚æœæ‰¾åˆ°åŒ¹é…ï¼Œå°±ä¸å˜—è©¦å…¶ä»–æ¨¡å¼
                print(f"DEBUG: Total responses collected: {len(responses)}")  # é™¤éŒ¯è³‡è¨Š
                break
    
    # å¦‚æœä¸Šé¢çš„æ¨¡å¼éƒ½æ²’åŒ¹é…åˆ°ï¼Œå˜—è©¦æ›´å¯¬æ³›çš„åˆ†å‰²æ–¹æ³•
    if not responses:
        # æŒ‰ç…§å¤šå€‹æ›è¡Œç¬¦åˆ†å‰²ï¼Œå°‹æ‰¾å¯èƒ½çš„é …ç›®
        sections = re.split(r'\n\n+', content)
        for section in sections:
            section = section.strip()
            if not section:
                continue
                
            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ•¸å­—ç·¨è™Ÿçš„é …ç›®
            if re.search(r'^\*?\*?\d+\.', section.strip(), re.MULTILINE):
                # é€²ä¸€æ­¥åˆ†å‰²é€™å€‹sectionä¸­çš„é …ç›®
                items = re.split(r'\n(?=\*?\*?\d+\.)', section)
                for item in items:
                    item = item.strip()
                    if item and re.match(r'^\*?\*?\d+\.', item):
                        # æ¸…ç†æ ¼å¼ä½†ä¿ç•™å®Œæ•´å…§å®¹
                        clean_item = re.sub(r'^\*?\*?(\d+)\.\s*', '', item)
                        if clean_item:
                            responses.append(clean_item)
    
    # å¦‚æœé‚„æ˜¯æ²’æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨åŸæœ‰çš„é‚è¼¯ä½œç‚ºæœ€å¾Œçš„å›é€€
    if not responses:
        lines = content.split('\n')
        current_item = ""
        
        for line in lines:
            line = line.strip()
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯æ–°é …ç›®çš„é–‹å§‹
            if line and (line.startswith('-') or line.startswith('â€¢') or 
                        any(line.startswith(f"{i}.") for i in range(1, 20)) or
                        any(line.startswith(f"**{i}.") for i in range(1, 20))):
                # å¦‚æœæœ‰å‰ä¸€å€‹é …ç›®ï¼Œå…ˆå„²å­˜
                if current_item:
                    clean_response = current_item.lstrip('-â€¢*0123456789. ').strip()
                    if clean_response:
                        responses.append(clean_response)
                
                # é–‹å§‹æ–°é …ç›®
                current_item = line
            elif current_item and line:
                # ç¹¼çºŒç•¶å‰é …ç›®çš„å…§å®¹
                current_item += "\n" + line
        
        # è™•ç†æœ€å¾Œä¸€å€‹é …ç›®
        if current_item:
            clean_response = current_item.lstrip('-â€¢*0123456789. ').strip()
            if clean_response:
                responses.append(clean_response)
    
    return responses[:10]  # é™åˆ¶æœ€å¤š10å€‹å›æ‡‰

def parse_chat_log_to_uses(input_file, output_file=None):
    """
    å¾ chat_log æª”æ¡ˆä¸­è§£æå‡º uses è³‡æ–™
    """
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        final_results = []
        
        for item_name, conversations in data.items():
            # è·³éç©ºçš„é …ç›®
            if not conversations:
                continue
                
            # æ‰¾åˆ°ç¬¬ä¸€å€‹æœ‰å°è©±å…§å®¹çš„ agent
            agent_name = None
            assistant_content = None
            
            for agent, conversation_list in conversations.items():
                if conversation_list:
                    agent_name = agent
                    # æ‰¾åˆ° assistant çš„å›ç­”
                    for conversation in conversation_list:
                        if conversation.get("role") == "assistant":
                            assistant_content = conversation.get("content", "")
                            break
                    if assistant_content:
                        break
            
            if assistant_content and agent_name:
                # è§£æ uses è³‡æ–™
                extracted_uses = extract_responses(assistant_content)
                if extracted_uses:  # åªæœ‰ç•¶è§£æå‡ºå…§å®¹æ™‚æ‰åŠ å…¥
                    final_results.append({
                        "item": item_name,
                        "uses": extracted_uses,
                        "Agent": agent_name
                    })
        
        # æ±ºå®šè¼¸å‡ºæª”æ¡ˆåç¨±
        if output_file is None:
            base_name = os.path.splitext(input_file)[0]
            output_file = f"{base_name}_parsed_uses.json"
        
        # å¯«å…¥è§£æå‡ºçš„ uses æª”æ¡ˆ
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æˆåŠŸè§£æï¼š{input_file}")
        print(f"âœ… è¼¸å‡ºæª”æ¡ˆï¼š{output_file}")
        print(f"ğŸ“Š è§£æå‡º {len(final_results)} å€‹é …ç›®")
        
        # é¡¯ç¤ºè§£æå‡ºçš„é …ç›®åç¨±
        if final_results:
            print("ğŸ” è§£æçš„é …ç›®ï¼š")
            for result in final_results[:5]:  # åªé¡¯ç¤ºå‰5å€‹
                print(f"   - {result['item']}")
            if len(final_results) > 5:
                print(f"   ... é‚„æœ‰ {len(final_results) - 5} å€‹é …ç›®")
        
        return True, output_file
        
    except Exception as e:
        print(f"âŒ è§£æå¤±æ•—ï¼š{e}")
        return False, None

def main():
    parser = argparse.ArgumentParser(description='å¾ chat_log æª”æ¡ˆä¸­è§£æ uses è³‡æ–™')
    parser.add_argument('input_file', help='è¼¸å…¥çš„ chat_log æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('-o', '--output', help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ (é è¨­ï¼šåœ¨è¼¸å…¥æª”æ¡ˆåç¨±å¾ŒåŠ ä¸Š _parsed_uses)')
    
    args = parser.parse_args()
    
    # æª¢æŸ¥è¼¸å…¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input_file):
        print(f"âŒ è¼¸å…¥æª”æ¡ˆä¸å­˜åœ¨ï¼š{args.input_file}")
        return
    
    # åŸ·è¡Œè§£æ
    success, output_file = parse_chat_log_to_uses(args.input_file, args.output)
    
    if success:
        print(f"\nğŸ‰ è§£æå®Œæˆï¼")
    else:
        print(f"\nğŸ’” è§£æå¤±æ•—ï¼")

if __name__ == "__main__":
    # å¦‚æœæ²’æœ‰å‘½ä»¤åˆ—åƒæ•¸ï¼Œè™•ç†ç•¶å‰ç›®éŒ„çš„é è¨­æª”æ¡ˆ
    import sys
    if len(sys.argv) == 1:
        # input_file = "/workspace/LLM_Persona/LLM-Discussion/Results/AUT/Output/persona_agent/AUT_persona_api_0918-0527_100_chat_log.json"
        input_file = "/workspace/LLM_Persona/LLM-Discussion/Results/Similarities/Output/persona_agent/Similarities_persona_api_0920-2032_100_chat_log.json"
        
        if os.path.exists(input_file):
            print(f"ğŸ”§ ä½¿ç”¨é è¨­æª”æ¡ˆï¼š{input_file}")
            success, output_file = parse_chat_log_to_uses(input_file)
        else:
            print(f"âŒ æ‰¾ä¸åˆ°é è¨­æª”æ¡ˆï¼š{input_file}")
            print("ğŸ’¡ è«‹æä¾›æª”æ¡ˆè·¯å¾‘ï¼Œä¾‹å¦‚ï¼š")
            print("   python parse_uses_only.py /path/to/chat_log.json")
    else:
        main()
