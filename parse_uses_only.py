#!/usr/bin/env python3
"""
ç´”ç²¹çš„ chat_log è§£æè…³æœ¬
å¾ chat_log æª”æ¡ˆä¸­æå– uses è³‡æ–™
"""

import json
import re
import argparse
import os

def extract_responses(content):
    """æå–å›æ‡‰å…§å®¹ï¼Œå¾ assistant çš„å›ç­”ä¸­è§£æå‡ºå…·é«”çš„ uses"""
    import re
    
    # å…ˆè™•ç†è¢«ç”¨æˆ¶è¼¸å…¥æˆªæ–·çš„å…§å®¹
    # ç§»é™¤ "user" é–‹å§‹çš„éƒ¨åˆ†å’Œå¾ŒçºŒå…§å®¹
    if '\nuser\n' in content:
        content = content.split('\nuser\n')[0]
    
    # å„ªåŒ–çš„æ­£è¦è¡¨é”å¼ï¼Œèƒ½è™•ç†å¤šç¨®æ ¼å¼
    patterns = [
        # æ ¼å¼1: 1. **Title**:** (å…§å®¹) - è™•ç†æ¨™é¡Œå¾Œæœ‰é¡å¤–å†’è™Ÿå’Œæ˜Ÿè™Ÿçš„æƒ…æ³
        r'(\d+)\.\s*\*\*([^*]+?)\*\*:?\*?:?\s*(.*?)(?=\d+\.\s*\*\*|$)',
        # æ ¼å¼2: **1.** **Title** (æ–°æ ¼å¼)
        r'\*\*(\d+)\.\*\*\s*\*\*([^*]+?)\*\*\s*(.*?)(?=\*\*\d+\.\*\*|$)',
        # æ ¼å¼3: **1. Title:** (å…§å®¹)
        r'\*\*(\d+)\.\s*([^*]+?)\*\*:?\s*(.*?)(?=\*\*\d+\.|$)',
        # æ ¼å¼4: 1. **Title:** (å…§å®¹)  
        r'(\d+)\.\s*\*\*([^*]+?)\*\*:?\s*(.*?)(?=\d+\.\s*\*\*|$)',
        # æ ¼å¼5: æ•¸å­—é–‹é ­çš„ä¸€èˆ¬é …ç›®
        r'(\d+)\.\s*([^\n]*?)\n(.*?)(?=\d+\.|$)'
    ]
    
    responses = []
    
    for pattern in patterns:
        matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
        if matches:
            for match in matches:
                if len(match) == 3:  # (number, title, content)
                    number = match[0].strip()
                    title = match[1].strip()
                    body = match[2].strip()
                    
                    # å»ºæ§‹å®Œæ•´é …ç›®
                    full_item = f"**{title}**"
                    if body:
                        full_item += f": {body}"
                    responses.append(full_item)
            
            if responses:  # å¦‚æœæ‰¾åˆ°åŒ¹é…ï¼Œå°±ä¸å˜—è©¦å…¶ä»–æ¨¡å¼
                break
    
    # å¦‚æœä¸Šé¢çš„æ¨¡å¼éƒ½æ²’åŒ¹é…åˆ°ï¼Œå˜—è©¦æ›´å¯¬æ³›çš„åˆ†å‰²æ–¹æ³•
    if not responses:
        # æŒ‰ç…§å¤šå€‹æ›è¡Œç¬¦åˆ†å‰²ï¼Œå°‹æ‰¾å¯èƒ½çš„é …ç›®
        sections = re.split(r'\n\n+', content)
        for section in sections:
            section = section.strip()
            if not section:
                continue
                
            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ•¸å­—ç·¨è™Ÿçš„é …ç›®
            if re.search(r'^\*?\*?\d+\.', section.strip(), re.MULTILINE):
                # é€²ä¸€æ­¥åˆ†å‰²é€™å€‹sectionä¸­çš„é …ç›®
                items = re.split(r'\n(?=\*?\*?\d+\.)', section)
                for item in items:
                    item = item.strip()
                    if item and re.match(r'^\*?\*?\d+\.', item):
                        # æ¸…ç†æ ¼å¼ä½†ä¿ç•™å®Œæ•´å…§å®¹
                        clean_item = re.sub(r'^\*?\*?(\d+)\.\s*', '', item)
                        if clean_item:
                            responses.append(clean_item)
    
    # å¦‚æœé‚„æ˜¯æ²’æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨åŸæœ‰çš„é‚è¼¯ä½œç‚ºæœ€å¾Œçš„å›é€€
    if not responses:
        lines = content.split('\n')
        current_item = ""
        
        for line in lines:
            line = line.strip()
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯æ–°é …ç›®çš„é–‹å§‹
            if line and (line.startswith('-') or line.startswith('â€¢') or 
                        any(line.startswith(f"{i}.") for i in range(1, 20)) or
                        any(line.startswith(f"**{i}.") for i in range(1, 20))):
                # å¦‚æœæœ‰å‰ä¸€å€‹é …ç›®ï¼Œå…ˆå„²å­˜
                if current_item:
                    clean_response = current_item.lstrip('-â€¢*0123456789. ').strip()
                    if clean_response:
                        responses.append(clean_response)
                
                # é–‹å§‹æ–°é …ç›®
                current_item = line
            elif current_item and line:
                # ç¹¼çºŒç•¶å‰é …ç›®çš„å…§å®¹
                current_item += "\n" + line
        
        # è™•ç†æœ€å¾Œä¸€å€‹é …ç›®
        if current_item:
            clean_response = current_item.lstrip('-â€¢*0123456789. ').strip()
            if clean_response:
                responses.append(clean_response)
    
    return responses[:10]  # é™åˆ¶æœ€å¤š10å€‹å›æ‡‰

def parse_chat_log_to_uses(input_file, output_file=None):
    """
    å¾ chat_log æª”æ¡ˆä¸­è§£æå‡º uses è³‡æ–™
    """
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        final_results = []
        
        for item_name, conversations in data.items():
            # è·³éç©ºçš„é …ç›®
            if not conversations:
                continue
                
            # æ‰¾åˆ°ç¬¬ä¸€å€‹æœ‰å°è©±å…§å®¹çš„ agent
            agent_name = None
            assistant_content = None
            
            for agent, conversation_list in conversations.items():
                if conversation_list:
                    agent_name = agent
                    # æ‰¾åˆ° assistant çš„å›ç­”
                    for conversation in conversation_list:
                        if conversation.get("role") == "assistant":
                            assistant_content = conversation.get("content", "")
                            break
                    if assistant_content:
                        break
            
            if assistant_content and agent_name:
                # è§£æ uses è³‡æ–™
                extracted_uses = extract_responses(assistant_content)
                if extracted_uses:  # åªæœ‰ç•¶è§£æå‡ºå…§å®¹æ™‚æ‰åŠ å…¥
                    final_results.append({
                        "item": item_name,
                        "uses": extracted_uses,
                        "Agent": agent_name
                    })
        
        # æ±ºå®šè¼¸å‡ºæª”æ¡ˆåç¨±
        if output_file is None:
            base_name = os.path.splitext(input_file)[0]
            output_file = f"{base_name}_parsed_uses.json"
        
        # å¯«å…¥è§£æå‡ºçš„ uses æª”æ¡ˆ
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æˆåŠŸè§£æï¼š{input_file}")
        print(f"âœ… è¼¸å‡ºæª”æ¡ˆï¼š{output_file}")
        print(f"ğŸ“Š è§£æå‡º {len(final_results)} å€‹é …ç›®")
        
        # é¡¯ç¤ºè§£æå‡ºçš„é …ç›®åç¨±
        if final_results:
            print("ğŸ” è§£æçš„é …ç›®ï¼š")
            for result in final_results[:5]:  # åªé¡¯ç¤ºå‰5å€‹
                print(f"   - {result['item']}")
            if len(final_results) > 5:
                print(f"   ... é‚„æœ‰ {len(final_results) - 5} å€‹é …ç›®")
        
        return True, output_file
        
    except Exception as e:
        print(f"âŒ è§£æå¤±æ•—ï¼š{e}")
        return False, None

def main():
    parser = argparse.ArgumentParser(description='å¾ chat_log æª”æ¡ˆä¸­è§£æ uses è³‡æ–™')
    parser.add_argument('input_file', help='è¼¸å…¥çš„ chat_log æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('-o', '--output', help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ (é è¨­ï¼šåœ¨è¼¸å…¥æª”æ¡ˆåç¨±å¾ŒåŠ ä¸Š _parsed_uses)')
    
    args = parser.parse_args()
    
    # æª¢æŸ¥è¼¸å…¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input_file):
        print(f"âŒ è¼¸å…¥æª”æ¡ˆä¸å­˜åœ¨ï¼š{args.input_file}")
        return
    
    # åŸ·è¡Œè§£æ
    success, output_file = parse_chat_log_to_uses(args.input_file, args.output)
    
    if success:
        print(f"\nğŸ‰ è§£æå®Œæˆï¼")
    else:
        print(f"\nğŸ’” è§£æå¤±æ•—ï¼")

if __name__ == "__main__":
    # å¦‚æœæ²’æœ‰å‘½ä»¤åˆ—åƒæ•¸ï¼Œè™•ç†ç•¶å‰ç›®éŒ„çš„é è¨­æª”æ¡ˆ
    import sys
    if len(sys.argv) == 1:
        # input_file = "/workspace/LLM_Persona/LLM-Discussion/Results/AUT/Output/persona_agent/AUT_persona_api_0918-0527_100_chat_log.json"
        input_file = "/workspace/LLM_Persona/LLM-Discussion/Results/Scientific/Output/persona_agent/Scientific_persona_api_0918-2154_100_chat_log.json"
        
        if os.path.exists(input_file):
            print(f"ğŸ”§ ä½¿ç”¨é è¨­æª”æ¡ˆï¼š{input_file}")
            success, output_file = parse_chat_log_to_uses(input_file)
        else:
            print(f"âŒ æ‰¾ä¸åˆ°é è¨­æª”æ¡ˆï¼š{input_file}")
            print("ğŸ’¡ è«‹æä¾›æª”æ¡ˆè·¯å¾‘ï¼Œä¾‹å¦‚ï¼š")
            print("   python parse_uses_only.py /path/to/chat_log.json")
    else:
        main()
