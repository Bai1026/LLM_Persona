from rich import print
from flask import Flask, request, jsonify
from datetime import datetime
import json
import traceback
from dotenv import load_dotenv, find_dotenv
from openai import OpenAI
import os
import re
from utils.log import colored_print

from self_play import discuss

load_dotenv(find_dotenv())

app = Flask(__name__)

# åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url=os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
)

@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    """
    ç°¡å–®çš„ OpenAI ç›¸å®¹ API ç«¯é»ï¼Œç´”ç²¹ç”¨æ–¼æ¸¬è©¦
    """
    try:
        # è§£æè«‹æ±‚è³‡æ–™
        data = request.get_json()
        
        if not data:
            return jsonify({
                "error": {
                    "message": "è«‹æ±‚ä¸»é«”å¿…é ˆæ˜¯æœ‰æ•ˆçš„ JSON",
                    "type": "invalid_request_error"
                }
            }), 400
        
        # é©—è­‰å¿…è¦æ¬„ä½
        if 'messages' not in data:
            return jsonify({
                "error": {
                    "message": "ç¼ºå°‘å¿…è¦æ¬„ä½: messages",
                    "type": "invalid_request_error"
                }
            }), 400
        
        messages = data['messages']
        model = data.get('model', 'gpt-4o-mini')
        temperature = data.get('temperature', 0.7)
        max_tokens = data.get('max_tokens', 1000)
        
        print(f'æ”¶åˆ° API è«‹æ±‚ - æ¨¡å‹: {model}, è¨Šæ¯æ•¸é‡: {len(messages)}')
        print(f'è¨Šæ¯å…§å®¹: {json.dumps(messages, ensure_ascii=False, indent=2)}')

        # ç°¡å–®çš„å›æ‡‰ç”Ÿæˆ - ç›´æ¥å‘¼å« OpenAI API
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",  # ä½¿ç”¨å›ºå®šæ¨¡å‹é€²è¡Œæ¸¬è©¦
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            generator_output = response.choices[0].message.content
            # generator_output, log = discuss(messages)
            
        except Exception as openai_error:
            print(f'OpenAI API éŒ¯èª¤: {str(openai_error)}')
        
        # return generator_output
        # å»ºç«‹ OpenAI æ ¼å¼çš„å›æ‡‰
        api_response = {
            "id": f"chatcmpl-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            "object": "chat.completion", 
            "created": int(datetime.now().timestamp()),
            "model": model,
            "choices": [
                {
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": generator_output
                    },
                    "finish_reason": "stop"
                }
            ],
            "usage": {
                "prompt_tokens": estimate_token_count(messages),
                "completion_tokens": estimate_token_count([{"role": "assistant", "content": generator_output}]),
                "total_tokens": estimate_token_count(messages) + estimate_token_count([{"role": "assistant", "content": generator_output}])
            }
        }
        
        print(f'API å›æ‡‰ç”¢ç”Ÿå®Œæˆ - é•·åº¦: {len(generator_output)} å­—å…ƒ')
        
        return jsonify(api_response)
        
    except Exception as e:
        print(f'API éŒ¯èª¤: {str(e)}')
        print(f'éŒ¯èª¤è¿½è¹¤: {traceback.format_exc()}')
        
        return jsonify({
            "error": {
                "message": f"å…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤: {str(e)}",
                "type": "internal_server_error"
            }
        }), 500

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "Simple Test API"
    })

@app.route('/models', methods=['GET'])
def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹ï¼ˆOpenAI ç›¸å®¹ï¼‰"""
    return jsonify({
        "object": "list",
        "data": [
            {
                "id": "test-model-v1",
                "object": "model", 
                "created": int(datetime.now().timestamp()),
                "owned_by": "custom"
            }
        ]
    })

def estimate_token_count(messages):
    """
    ç°¡å–®çš„ token æ•¸é‡ä¼°è¨ˆå‡½å¼
    """
    total_chars = sum(len(msg.get('content', '')) for msg in messages)
    # ç²—ç•¥ä¼°è¨ˆï¼š1 token â‰ˆ 4 å­—å…ƒï¼ˆä¸­æ–‡å¯èƒ½æ›´å°‘ï¼‰
    return max(1, total_chars // 3)

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        "error": {
            "message": "æ‰¾ä¸åˆ°è«‹æ±‚çš„ç«¯é»",
            "type": "not_found_error"
        }
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        "error": {
            "message": "å…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤",
            "type": "internal_server_error"
        }
    }), 500

if __name__ == '__main__':
    print('ğŸš€ å•Ÿå‹•ç°¡å–®æ¸¬è©¦ API ä¼ºæœå™¨...')
    print('ğŸ“¡ API ç«¯é»: http://localhost:6969/v1/chat/completions')
    print('ğŸ’Š å¥åº·æª¢æŸ¥: http://localhost:6969/health')
    print('ğŸ“‹ æ¨¡å‹åˆ—è¡¨: http://localhost:6969/models')
    
    app.run(
        host='0.0.0.0',
        port=6969,
        debug=True,
        threaded=True
    )