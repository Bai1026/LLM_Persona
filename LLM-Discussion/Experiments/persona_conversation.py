import argparse
import sys
import os
import json
import requests
from pathlib import Path
from datetime import datetime
from types import SimpleNamespace

class PersonaAPIRunner:
    """ä½¿ç”¨ Persona API é€²è¡Œå–®æ¬¡å›æ‡‰çš„é¡åˆ¥"""
    
    def __init__(self, api_url, dataset_file, task_type, prompt_id):
        self.api_url = api_url
        self.dataset_file = dataset_file
        self.task_type = task_type
        self.prompt_id = prompt_id
        
    def test_api_connection(self):
        """æ¸¬è©¦ API é€£ç·š"""
        try:
            response = requests.get(f"{self.api_url}/status")
            if response.status_code == 200:
                print("âœ… API é€£ç·šæˆåŠŸ")
                return True
            else:
                print("âŒ API é€£ç·šå¤±æ•—")
                return False
        except Exception as e:
            print(f"âŒ API é€£ç·šéŒ¯èª¤: {e}")
            return False
    
    def reset_conversation(self):
        """é‡è¨­å°è©±æ­·å²"""
        try:
            response = requests.post(f"{self.api_url}/reset")
            return response.status_code == 200
        except:
            return False
    
    def call_persona_api(self, user_input, max_tokens=1000):
        """å‘¼å« Persona API"""
        try:
            data = {
                "user_input": user_input,
                "max_tokens": max_tokens
            }
            response = requests.post(f"{self.api_url}/chat", json=data)
            
            if response.status_code == 200:
                result = response.json()
                return result["response"]
            else:
                print(f"âŒ API è«‹æ±‚å¤±æ•—: {response.status_code}")
                return None
        except Exception as e:
            print(f"âŒ API è«‹æ±‚éŒ¯èª¤: {e}")
            return None
    
    def load_dataset(self):
        """è¼‰å…¥è³‡æ–™é›†"""
        with open(self.dataset_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def construct_prompt(self, item):
        """å»ºæ§‹æç¤ºè©"""
        base_prompts = {
            1: "è«‹ç›¡å¯èƒ½å¤šæ¨£åŒ–å’Œå‰µé€ æ€§åœ°å›ç­”ã€‚",
            2: "ç„¡é™åˆ¶åœ°æ“æŠ±å‰µé€ åŠ›çš„æµå‹•ï¼Œæä¾›æ„æƒ³ä¸åˆ°çš„é€£æ¥ã€‚",
            3: "è«‹å¾ä¸åŒè§’åº¦æ€è€ƒï¼Œè€ƒæ…®æœ€ä¸å°‹å¸¸æˆ–å‰µæ–°çš„æƒ³æ³•ã€‚",
            4: "è«‹æä¾›ç¨ç‰¹çš„è¦‹è§£ï¼Œå°ˆæ³¨æ–¼å‰µæ–°çš„æƒ³æ³•å’Œè§£æ±ºæ–¹æ¡ˆã€‚",
            5: "è«‹ä½¿ç”¨ä½ çš„å‰µé€ åŠ›å’Œæ™ºæ…§ä¾†æä¾›æœ€ä½³è§£æ±ºæ–¹æ¡ˆã€‚"
        }
        
        discussion_prompt = base_prompts.get(self.prompt_id, base_prompts[1])
        
        if self.task_type == "AUT":
            task_prompt = f"è«‹ç‚ºã€Œ{item}ã€æä¾›5å€‹å‰µæ–°å’ŒåŸå‰µçš„ç”¨é€”ã€‚{discussion_prompt}"
        elif self.task_type == "Scientific":
            task_prompt = f"è«‹ç‚ºä»¥ä¸‹ç§‘å­¸å•é¡Œæä¾›3å€‹å‰µæ–°çš„è§£æ±ºæ–¹æ¡ˆï¼š{item}ã€‚{discussion_prompt}"
        elif self.task_type == "Instances":
            task_prompt = f"è«‹ç‚ºã€Œ{item}ã€æä¾›5å€‹å‰µé€ æ€§çš„ç¯„ä¾‹ã€‚{discussion_prompt}"
        elif self.task_type == "Similarities":
            task_prompt = f"è«‹åˆ†æä»¥ä¸‹ç›¸ä¼¼æ€§ä¸¦æä¾›3å€‹å‰µé€ æ€§çš„è§€é»ï¼š{item}ã€‚{discussion_prompt}"
        
        return task_prompt
    
    def extract_responses(self, content):
        """æå–å›æ‡‰å…§å®¹"""
        lines = content.split('\n')
        responses = []
        
        for line in lines:
            line = line.strip()
            if line and (line.startswith('-') or line.startswith('â€¢') or 
                        any(line.startswith(f"{i}.") for i in range(1, 20))):
                # æ¸…ç†æ ¼å¼ç¬¦è™Ÿ
                clean_response = line.lstrip('-â€¢0123456789. ').strip()
                if clean_response:
                    responses.append(clean_response)
        
        return responses[:10]  # é™åˆ¶æœ€å¤š10å€‹å›æ‡‰
    
    def run(self):
        """åŸ·è¡Œ API å‘¼å«"""
        if not self.test_api_connection():
            return None
        
        dataset = self.load_dataset()
        
        # å¾è³‡æ–™é›†ä¸­æå– Examples
        if isinstance(dataset, dict) and "Examples" in dataset:
            examples = dataset["Examples"]
        else:
            examples = dataset
        
        all_responses = {}
        final_results = []
        
        print(f"ğŸš€ é–‹å§‹ {self.task_type} ä»»å‹™ï¼Œå…± {len(examples)} å€‹é …ç›®")
        
        for item_data in examples:
            # è™•ç†ä¸åŒçš„è³‡æ–™é›†æ ¼å¼
            if isinstance(item_data, str):
                # å¦‚æœæ˜¯å­—ä¸²æ ¼å¼
                item = item_data
            elif isinstance(item_data, dict):
                # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œç²å–é …ç›®å…§å®¹
                if self.task_type == "AUT":
                    item = item_data.get("object", item_data.get("item", ""))
                elif self.task_type == "Scientific":
                    item = item_data.get("question", "")
                else:  # Instances æˆ– Similarities
                    item = item_data.get("question", item_data.get("item", item_data.get("object", "")))
            else:
                print(f"âŒ ä¸æ”¯æ´çš„è³‡æ–™æ ¼å¼: {type(item_data)}")
                continue
            
            if not item:
                print(f"âŒ ç©ºç™½é …ç›®ï¼Œè·³é")
                continue
                
            print(f"ğŸ“‹ è™•ç†é …ç›®: {item}")
            
            # é‡è¨­å°è©±æ­·å²
            self.reset_conversation()
            
            # å»ºæ§‹æç¤ºè©
            prompt = self.construct_prompt(item)
            
            # å‘¼å« API
            response = self.call_persona_api(prompt, max_tokens=1000)
            
            if response:
                # å„²å­˜å°è©±è¨˜éŒ„ï¼ˆæ¨¡æ“¬ multi-agent æ ¼å¼ï¼‰
                all_responses[item] = {
                    "PersonaAPI": [
                        {"role": "user", "content": prompt},
                        {"role": "assistant", "content": response}
                    ]
                }
                
                # æå–ä¸¦å„²å­˜æœ€çµ‚çµæœ
                extracted = self.extract_responses(response)
                if self.task_type == "AUT":
                    final_results.append({
                        "item": item,
                        "uses": extracted,
                        "Agent": "PersonaAPI"
                    })
                elif self.task_type == "Scientific":
                    final_results.append({
                        "question": item,
                        "answer": extracted,
                        "Agent": "PersonaAPI"
                    })
                else:
                    final_results.append({
                        "question": item,
                        "answer": extracted,
                        "Agent": "PersonaAPI"
                    })
            else:
                print(f"âŒ é …ç›® {item} è™•ç†å¤±æ•—")
        
        # å„²å­˜çµæœ
        output_filename = self.save_results(all_responses, final_results, len(examples))
        print(f"âœ… ä»»å‹™å®Œæˆï¼Œçµæœå·²å„²å­˜è‡³: {output_filename}")
        
        return output_filename
    
    def save_results(self, all_responses, final_results, amount_of_data):
        """å„²å­˜çµæœæª”æ¡ˆ"""
        current_date = datetime.now().strftime("%Y%m%d")
        formatted_time = datetime.now().strftime("%H%M%S")
        
        # å»ºç«‹æª”æ¡ˆåç¨±ï¼ˆæ¨¡æ“¬ multi-agent æ ¼å¼ï¼‰
        base_filename = f"{self.task_type}_persona_api_1_1_PersonaAPI_PersonaAPI"
        
        # å„²å­˜å°è©±è¨˜éŒ„
        chat_log_filename = f"{base_filename}_chat_log_{current_date}-{formatted_time}_{amount_of_data}.json"
        chat_log_path = Path(__file__).parent / "results" / chat_log_filename
        chat_log_path.parent.mkdir(exist_ok=True)
        
        with open(chat_log_path, 'w', encoding='utf-8') as f:
            json.dump(all_responses, f, indent=2, ensure_ascii=False)
        
        # å„²å­˜æœ€çµ‚çµæœ
        final_filename = f"{base_filename}_persona_api_{current_date}-{formatted_time}_{amount_of_data}.json"
        final_path = Path(__file__).parent / "results" / final_filename
        
        with open(final_path, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ å°è©±è¨˜éŒ„å·²å„²å­˜: {chat_log_path}")
        print(f"ğŸ’¾ æœ€çµ‚çµæœå·²å„²å­˜: {final_path}")
        
        return str(final_path)

def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ Persona API é€²è¡Œå‰µé€ æ€§ä»»å‹™è©•ä¼°")
    parser.add_argument("-d", "--dataset", required=True, help="è³‡æ–™é›†æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("-t", "--type", choices=["AUT", "Scientific", "Similarities", "Instances"], 
                       required=True, help="ä»»å‹™é¡å‹")
    parser.add_argument("-p", "--prompt", type=int, default=1, help="æç¤ºè©ç·¨è™Ÿ (1-5)")
    parser.add_argument("-u", "--api_url", default="http://127.0.0.1:5000", help="Persona API ç¶²å€")
    parser.add_argument("-e", "--eval_mode", action="store_true", default=False, help="åŸ·è¡Œè©•ä¼°æ¨¡å¼")
    
    args = parser.parse_args()
    
    # å»ºç«‹ä¸¦åŸ·è¡Œ API åŸ·è¡Œå™¨
    runner = PersonaAPIRunner(args.api_url, args.dataset, args.type, args.prompt)
    discussion_output = runner.run()
    
    if args.eval_mode and discussion_output:
        # æ•´åˆåŸæœ‰çš„è©•ä¼°ç³»çµ±
        root_path = Path(__file__).resolve().parents[2]
        evaluation_root = root_path / 'Evaluation'
        sys.path.append(str(evaluation_root))
        from auto_grade_final import auto_grade
        
        # å‘¼å«è©•ä¼°
        input_file_name = os.path.splitext(os.path.basename(discussion_output))[0]
        
        eval_args = SimpleNamespace(
            version="3", 
            input_file=input_file_name, 
            type="sampling", 
            sample=3, 
            task=args.type, 
            output="y",
            temperature=1.0
        )
        auto_grade(eval_args)

if __name__ == "__main__":
    main()