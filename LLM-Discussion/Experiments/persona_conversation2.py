import argparse
import sys
import os
import json
import requests
from pathlib import Path
from datetime import datetime
from types import SimpleNamespace
import pytz

class PersonaAPIRunner:
    """ä½¿ç”¨ Persona API é€²è¡Œå–®æ¬¡å›æ‡‰çš„é¡åˆ¥"""
    
    def __init__(self, api_url, dataset_file, task_type, prompt_id):
        self.api_url = api_url
        self.dataset_file = dataset_file
        self.task_type = task_type
        self.prompt_id = prompt_id
        
    def test_api_connection(self):
        """æ¸¬è©¦ API é€£ç·š"""
        try:
            response = requests.get(f"{self.api_url}/status")
            if response.status_code == 200:
                print("âœ… API é€£ç·šæˆåŠŸ")
                return True
            else:
                print("âŒ API é€£ç·šå¤±æ•—")
                return False
        except Exception as e:
            print(f"âŒ API é€£ç·šéŒ¯èª¤: {e}")
            return False
    
    def reset_conversation(self):
        """é‡è¨­å°è©±æ­·å²"""
        try:
            response = requests.post(f"{self.api_url}/reset")
            return response.status_code == 200
        except:
            return False
    
    def call_persona_api(self, user_input, max_tokens=1000):
        """å‘¼å« Persona API"""
        try:
            data = {
                "user_input": user_input,
                "max_tokens": max_tokens
            }
            response = requests.post(f"{self.api_url}/chat", json=data)
            
            if response.status_code == 200:
                result = response.json()
                return result["response"]
            else:
                print(f"âŒ API è«‹æ±‚å¤±æ•—: {response.status_code}")
                return None
        except Exception as e:
            print(f"âŒ API è«‹æ±‚éŒ¯èª¤: {e}")
            return None
    
    def load_dataset(self):
        """è¼‰å…¥è³‡æ–™é›†"""
        with open(self.dataset_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def construct_prompt(self, item):
        """å»ºæ§‹æç¤ºè©"""
        # å°‡ LLM Discussion çš„å”ä½œæç¤ºè©æ”¹ç‚ºå–®ä¸€ä»£ç†ç‰ˆæœ¬
        base_prompts = {
            1: "You are working on a creative task; as a result, answer as diversely and creatively as you can.",
            2: "You're in a brainstorming session where each idea leads to the next. Embrace the flow of creativity without limits, building on suggestions for unexpected connections.",
            3: "Pretend you are at a think tank where unconventional ideas are the norm. Challenge yourself to think from different perspectives, considering the most unusual or innovative ideas.",
            4: "Engage in a creative thinking process where you contribute unique insights and queries, aiming to delve into uncharted territories of thought. Focus on expanding the scope and depth of your contribution through innovative thinking, counterpoints, and further questioning. The objective is to achieve a broad spectrum of ideas and solutions, promoting continuous learning and innovation.",
            5: "Envision yourself as an expert on a mission to solve a challenge using only your creativity and wit. How would you piece together clues from different perspectives to find the solution? This would be crucial to the success of the mission."
        }
        
        # use the -p parameter
        discussion_prompt = base_prompts.get(self.prompt_id, base_prompts[1])
        
        if self.task_type == "AUT":
            # # ä½¿ç”¨èˆ‡ LLM Discussion ç›¸åŒçš„å®Œæ•´ä»»å‹™æè¿°æ ¼å¼, this does not work well for Qwen and Llama
            # task_description = f"What are some creative use for {item}? The goal is to come up with creative ideas, which are ideas that strike people as clever, unusual, interesting, uncommon, humorous, innovative, or different. Present a list of as many creative and diverse uses for {item} as possible."
            # task_prompt = f"Can you answer the following question as creatively as possible: {task_description} {discussion_prompt} Please put your answer in a list format, starting with 1. ... 2. ... 3. ... and so on."

            # Test-1
            task_prompt = f"Please provide 5 innovative and original uses for '{item}'. {discussion_prompt}"

            # Test-2
            # task_prompt = f"Please provide some innovative and original uses for '{item}'. {discussion_prompt}"

            # Task-3
            # task_prompt = f"Please provide 10 innovative and original uses for '{item}'. {discussion_prompt}"

        elif self.task_type == "Scientific":
            task_prompt = f"Can you answer the following scientific question as creatively as possible: {item} {discussion_prompt} Please provide 5 innovative solutions in a list format, starting with 1. ... 2. ... 3. ..."
        elif self.task_type == "Instances":
            task_prompt = f"Can you answer the following question as creatively as possible: {item} {discussion_prompt} Please provide 5 creative examples in a list format, starting with 1. ... 2. ... 3. ... and so on."
        elif self.task_type == "Similarities":
            task_prompt = f"Can you answer the following question as creatively as possible: {item} {discussion_prompt} Please provide 5 creative perspectives in a list format, starting with 1. ... 2. ... 3. ..."
        
        return task_prompt
    
    # # Chinese version of construct_prompt (better for Qwen and Llama)
    # def construct_prompt(self, item):
    #     """å»ºæ§‹æç¤ºè©"""
    #     base_prompts = {
    #         1: "è«‹ç›¡å¯èƒ½å¤šæ¨£åŒ–å’Œå‰µé€ æ€§åœ°å›ç­”ã€‚",
    #         2: "ç„¡é™åˆ¶åœ°æ“æŠ±å‰µé€ åŠ›çš„æµå‹•ï¼Œæä¾›æ„æƒ³ä¸åˆ°çš„é€£æ¥ã€‚",
    #         3: "è«‹å¾ä¸åŒè§’åº¦æ€è€ƒï¼Œè€ƒæ…®æœ€ä¸å°‹å¸¸æˆ–å‰µæ–°çš„æƒ³æ³•ã€‚",
    #         4: "è«‹æä¾›ç¨ç‰¹çš„è¦‹è§£ï¼Œå°ˆæ³¨æ–¼å‰µæ–°çš„æƒ³æ³•å’Œè§£æ±ºæ–¹æ¡ˆã€‚",
    #         5: "è«‹ä½¿ç”¨ä½ çš„å‰µé€ åŠ›å’Œæ™ºæ…§ä¾†æä¾›æœ€ä½³è§£æ±ºæ–¹æ¡ˆã€‚"
    #     }
        
    #     discussion_prompt = base_prompts.get(self.prompt_id, base_prompts[1])
        
    #     if self.task_type == "AUT":
    #         task_prompt = f"è«‹ç‚ºã€Œ{item}ã€æä¾›5å€‹å‰µæ–°å’ŒåŸå‰µçš„ç”¨é€”ã€‚{discussion_prompt}"
    #     elif self.task_type == "Scientific":
    #         task_prompt = f"è«‹ç‚ºä»¥ä¸‹ç§‘å­¸å•é¡Œæä¾›5å€‹å‰µæ–°çš„è§£æ±ºæ–¹æ¡ˆï¼š{item}ã€‚{discussion_prompt}"
    #     elif self.task_type == "Instances":
    #         task_prompt = f"è«‹ç‚ºã€Œ{item}ã€æä¾›5å€‹å‰µé€ æ€§çš„ç¯„ä¾‹ã€‚{discussion_prompt}"
    #     elif self.task_type == "Similarities":
    #         task_prompt = f"è«‹åˆ†æä»¥ä¸‹ç›¸ä¼¼æ€§ä¸¦æä¾›5å€‹å‰µé€ æ€§çš„è§€é»ï¼š{item}ã€‚{discussion_prompt}"
        
    #     return task_prompt

    def extract_responses(self, content):
        """æå–å›æ‡‰å…§å®¹ï¼Œå¾ assistant çš„å›ç­”ä¸­è§£æå‡ºå…·é«”çš„ uses"""
        import re
        
        # é¦–å…ˆå˜—è©¦æå–å®Œæ•´çš„å›æ‡‰ï¼ŒåŒ…æ‹¬è¢« user ä¸­æ–·å¾Œçš„å…§å®¹
        enhanced_content = content
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ \nuser\n ä¸­æ–·
        user_match = re.search(r'\nuser\n', content)
        if user_match:
            # ç²å–è¢«æˆªæ–·å‰çš„å…§å®¹
            before_user = content[:user_match.start()]
            after_user_section = content[user_match.end():]
            
            # è·³éç”¨æˆ¶çš„è¼¸å…¥ï¼Œæ‰¾åˆ°å¾ŒçºŒçš„å›æ‡‰
            lines_after_user = after_user_section.split('\n')
            assistant_response_lines = []
            skip_user_input = True
            
            for line in lines_after_user:
                line = line.strip()
                # è·³éç”¨æˆ¶çš„æŒ‡ä»¤éƒ¨åˆ†
                if skip_user_input:
                    if line.startswith(('Continue', 'Now', 'Imagine', 'Tell me', 'What', 'How')):
                        continue
                    elif line == '' or len(line) < 10:
                        continue
                    else:
                        skip_user_input = False
                
                # æ”¶é›†åŠ©ç†çš„å›æ‡‰
                if not skip_user_input and line:
                    assistant_response_lines.append(line)
            
            # å¦‚æœæ‰¾åˆ°å¾ŒçºŒçš„åŠ©ç†å›æ‡‰ï¼Œå°‡å…¶åˆä½µ
            if assistant_response_lines:
                additional_response = ' '.join(assistant_response_lines)
                # æª¢æŸ¥ before_user æ˜¯å¦ä»¥ä¸å®Œæ•´çš„å¥å­çµå°¾
                if before_user.rstrip().endswith(('like', '(', 'such as', 'including', 'with')):
                    # å˜—è©¦æ™ºæ…§åœ°é€£æ¥å…§å®¹
                    enhanced_content = before_user.rstrip() + ' ' + additional_response
                else:
                    enhanced_content = before_user
            else:
                enhanced_content = before_user
        
        # ç§»é™¤å…¶ä»–å¯èƒ½çš„æˆªæ–·æ¨™è¨˜
        cleanup_patterns = [
            r'\nContinue.*',
            r'\nNow.*',
            r'\nImagine.*'
        ]
        
        for pattern in cleanup_patterns:
            match = re.search(pattern, enhanced_content, re.DOTALL | re.IGNORECASE)
            if match:
                enhanced_content = enhanced_content[:match.start()]
        
        content = enhanced_content
        
        # å„ªåŒ–çš„æ­£è¦è¡¨é”å¼ï¼Œèƒ½è™•ç†å¤šç¨®æ ¼å¼
        patterns = [
            # æ ¼å¼1: 1. **Title** (å¯é¸å†’è™Ÿ) - æ”¹é€²ç‰ˆæœ¬ï¼Œèƒ½è™•ç†æ··åˆæ ¼å¼
            r'(\d+)\.\s*\*\*([^*]+?)\*\*:?\s*\n?(.*?)(?=\d+\.\s*\*\*|$)',
            # æ ¼å¼2: **1.** **Title** (æ–°æ ¼å¼)
            r'\*\*(\d+)\.\*\*\s*\*\*([^*]+?)\*\*\s*(.*?)(?=\*\*\d+\.\*\*|$)',
            # æ ¼å¼3: **1. Title:** (å…§å®¹)
            r'\*\*(\d+)\.\s*([^*]+?)\*\*:?\s*(.*?)(?=\*\*\d+\.|$)',
            # æ ¼å¼4: 1. **Title:** (å…§å®¹)  
            r'(\d+)\.\s*\*\*([^*]+?)\*\*:?\s*(.*?)(?=\d+\.\s*\*\*|$)',
            # æ ¼å¼5: æ•¸å­—é–‹é ­çš„ä¸€èˆ¬é …ç›®
            r'(\d+)\.\s*([^\n]*?)\n(.*?)(?=\d+\.|$)'
        ]
        
        responses = []
        
        for i, pattern in enumerate(patterns):
            matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
            # print(f"DEBUG: Pattern {i+1} found {len(matches)} matches")  # é™¤éŒ¯è³‡è¨Š
            if matches:
                for j, match in enumerate(matches):
                    if len(match) == 3:  # (number, title, content)
                        number = match[0].strip()
                        title = match[1].strip()
                        body = match[2].strip()
                        
                        # print(f"DEBUG: Processing match {j+1}: '{title}', body length: {len(body)}")
                        
                        # æ¸…ç†é‡è¤‡çš„å…§å®¹
                        # original_body_length = len(body)
                        # body = self.clean_repetitive_content(body)
                        # cleaned_body_length = len(body)
                        
                        # print(f"DEBUG: Body length after cleaning: {original_body_length} -> {cleaned_body_length}")
                        
                        # å»ºæ§‹å®Œæ•´é …ç›®
                        full_item = f"**{title}**"
                        if body:
                            full_item += f": {body}"
                        responses.append(full_item)
                        # print(f"DEBUG: Added response: {title}")  # é™¤éŒ¯è³‡è¨Š
                
                if responses:  # å¦‚æœæ‰¾åˆ°åŒ¹é…ï¼Œå°±ä¸å˜—è©¦å…¶ä»–æ¨¡å¼
                    print(f"DEBUG: Total responses collected: {len(responses)}")  # é™¤éŒ¯è³‡è¨Š
                    break
        
        # å¦‚æœä¸Šé¢çš„æ¨¡å¼éƒ½æ²’åŒ¹é…åˆ°ï¼Œå˜—è©¦æ›´å¯¬æ³›çš„åˆ†å‰²æ–¹æ³•
        if not responses:
            # æŒ‰ç…§å¤šå€‹æ›è¡Œç¬¦åˆ†å‰²ï¼Œå°‹æ‰¾å¯èƒ½çš„é …ç›®
            sections = re.split(r'\n\n+', content)
            for section in sections:
                section = section.strip()
                if not section:
                    continue
                    
                # æª¢æŸ¥æ˜¯å¦åŒ…å«æ•¸å­—ç·¨è™Ÿçš„é …ç›®
                if re.search(r'^\*?\*?\d+\.', section.strip(), re.MULTILINE):
                    # é€²ä¸€æ­¥åˆ†å‰²é€™å€‹sectionä¸­çš„é …ç›®
                    items = re.split(r'\n(?=\*?\*?\d+\.)', section)
                    for item in items:
                        item = item.strip()
                        if item and re.match(r'^\*?\*?\d+\.', item):
                            # æ¸…ç†æ ¼å¼ä½†ä¿ç•™å®Œæ•´å…§å®¹
                            clean_item = re.sub(r'^\*?\*?(\d+)\.\s*', '', item)
                            if clean_item:
                                responses.append(clean_item)
        
        # å¦‚æœé‚„æ˜¯æ²’æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨åŸæœ‰çš„é‚è¼¯ä½œç‚ºæœ€å¾Œçš„å›é€€
        if not responses:
            lines = content.split('\n')
            current_item = ""
            
            for line in lines:
                line = line.strip()
                
                # æª¢æŸ¥æ˜¯å¦æ˜¯æ–°é …ç›®çš„é–‹å§‹
                if line and (line.startswith('-') or line.startswith('â€¢') or 
                            any(line.startswith(f"{i}.") for i in range(1, 20)) or
                            any(line.startswith(f"**{i}.") for i in range(1, 20))):
                    # å¦‚æœæœ‰å‰ä¸€å€‹é …ç›®ï¼Œå…ˆå„²å­˜
                    if current_item:
                        clean_response = current_item.lstrip('-â€¢*0123456789. ').strip()
                        if clean_response:
                            responses.append(clean_response)
                    
                    # é–‹å§‹æ–°é …ç›®
                    current_item = line
                elif current_item and line:
                    # ç¹¼çºŒç•¶å‰é …ç›®çš„å…§å®¹
                    current_item += "\n" + line
            
            # è™•ç†æœ€å¾Œä¸€å€‹é …ç›®
            if current_item:
                clean_response = current_item.lstrip('-â€¢*0123456789. ').strip()
                if clean_response:
                    responses.append(clean_response)
        
        return responses[:10]  # é™åˆ¶æœ€å¤š10å€‹å›æ‡‰
    
    def run(self):
        """åŸ·è¡Œ API å‘¼å«"""
        if not self.test_api_connection():
            return None
        
        dataset = self.load_dataset()
        
        # æ ¹æ“šä»»å‹™é¡å‹æå–è³‡æ–™
        if self.task_type == "Scientific":
            # Scientific è³‡æ–™é›†æ ¼å¼ï¼š{"Task": [{"Original": "...", "Example": [...]}]}
            examples = []
            for task in dataset.get("Task", []):
                examples.extend(task.get("Example", []))
        elif isinstance(dataset, dict) and "Examples" in dataset:
            # AUT, Instances, Similarities æ ¼å¼ï¼š{"Examples": [...]}
            examples = dataset["Examples"]
        else:
            examples = dataset
        
        all_responses = {}
        final_results = []
        
        print(f"ğŸš€ é–‹å§‹ {self.task_type} ä»»å‹™ï¼Œå…± {len(examples)} å€‹é …ç›®")
        
        from tqdm import tqdm
        for item_data in tqdm(examples):
            # è™•ç†ä¸åŒçš„è³‡æ–™é›†æ ¼å¼
            if isinstance(item_data, str):
                # å¦‚æœæ˜¯å­—ä¸²æ ¼å¼ï¼ˆScientific, Instances, Similarities é€šå¸¸æ˜¯é€™ç¨®æ ¼å¼ï¼‰
                item = item_data
            elif isinstance(item_data, dict):
                # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œç²å–é …ç›®å…§å®¹
                if self.task_type == "AUT":
                    item = item_data.get("object", item_data.get("item", ""))
                elif self.task_type == "Scientific":
                    item = item_data.get("question", item_data.get("item", ""))
                else:  # Instances æˆ– Similarities
                    item = item_data.get("question", item_data.get("item", item_data.get("object", "")))
            else:
                print(f"âŒ ä¸æ”¯æ´çš„è³‡æ–™æ ¼å¼: {type(item_data)}")
                continue
            
            if not item:
                print(f"âŒ ç©ºç™½é …ç›®ï¼Œè·³é")
                continue
                
            print(f"ğŸ“‹ è™•ç†é …ç›®: {item}")
            
            # é‡è¨­å°è©±æ­·å²
            self.reset_conversation()
            
            # å»ºæ§‹æç¤ºè©
            prompt = self.construct_prompt(item)
            
            # å‘¼å« API
            response = self.call_persona_api(prompt, max_tokens=1000)
            
            if response:
                # å„²å­˜å°è©±è¨˜éŒ„ï¼ˆæ¨¡æ“¬ multi-agent æ ¼å¼ï¼‰
                all_responses[item] = {
                    "PersonaAPI": [
                        {"role": "user", "content": prompt},
                        {"role": "assistant", "content": response}
                    ]
                }
                
                # æå–ä¸¦å„²å­˜æœ€çµ‚çµæœ
                extracted = self.extract_responses(response)
                if self.task_type == "AUT":
                    final_results.append({
                        "item": item,
                        "uses": extracted,
                        "Agent": "PersonaAPI"
                    })
                elif self.task_type == "Scientific":
                    final_results.append({
                        "question": item,
                        "answer": extracted,
                        "Agent": "PersonaAPI"
                    })
                else:
                    final_results.append({
                        "question": item,
                        "answer": extracted,
                        "Agent": "PersonaAPI"
                    })
            else:
                print(f"âŒ é …ç›® {item} è™•ç†å¤±æ•—")
        
        # å„²å­˜çµæœ
        output_filename = self.save_results(all_responses, final_results, len(examples))
        print(f"âœ… ä»»å‹™å®Œæˆï¼Œçµæœå·²å„²å­˜è‡³: {output_filename}")
        
        return output_filename
    
    def save_results(self, all_responses, final_results, amount_of_data):
        """å„²å­˜çµæœæª”æ¡ˆ"""
        # ä½¿ç”¨ UTC+8 æ™‚å€ï¼ˆå°ç£æ™‚é–“ï¼‰
        taipei_tz = pytz.timezone('Asia/Taipei')
        taipei_time = datetime.now(taipei_tz)
        
        current_date = taipei_time.strftime("%m%d")
        formatted_time = taipei_time.strftime("%H%M")
        
        # å»ºç«‹æª”æ¡ˆåç¨±ï¼ˆç¬¦åˆè©•ä¼°ç³»çµ±æ ¼å¼ï¼‰
        base_filename = f"{self.task_type}_persona_api_{current_date}-{formatted_time}_{amount_of_data}"
        
        # è©•ä¼°ç³»çµ±æœŸå¾…çš„è·¯å¾‘çµæ§‹ï¼šResults/{task}/Output/{agent}_agent/
        results_base_path = Path(__file__).parent.parent / "Results" / self.task_type / "Output" / "persona_agent"
        results_base_path.mkdir(parents=True, exist_ok=True)
        
        # å„²å­˜å°è©±è¨˜éŒ„
        chat_log_filename = f"{base_filename}_chat_log.json"
        chat_log_path = results_base_path / chat_log_filename
        
        with open(chat_log_path, 'w', encoding='utf-8') as f:
            json.dump(all_responses, f, indent=2, ensure_ascii=False)
        
        # å„²å­˜æœ€çµ‚çµæœï¼ˆé€™æ˜¯è©•ä¼°ç³»çµ±éœ€è¦çš„æª”æ¡ˆï¼‰
        final_filename = f"{base_filename}.json"
        final_path = results_base_path / final_filename
        
        with open(final_path, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ å°è©±è¨˜éŒ„å·²å„²å­˜: {chat_log_path}")
        print(f"ğŸ’¾ æœ€çµ‚çµæœå·²å„²å­˜: {final_path}")
        
        # å›å‚³æª”æ¡ˆåç¨±ï¼ˆä¸å«å‰¯æª”åï¼Œä¾›è©•ä¼°ä½¿ç”¨ï¼‰
        return final_filename.replace('.json', '')

def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ Persona API é€²è¡Œå‰µé€ æ€§ä»»å‹™è©•ä¼°")
    parser.add_argument("-d", "--dataset", required=True, help="è³‡æ–™é›†æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("-t", "--type", choices=["AUT", "Scientific", "Similarities", "Instances"], 
                       required=True, help="ä»»å‹™é¡å‹")
    parser.add_argument("-p", "--prompt", type=int, default=1, help="æç¤ºè©ç·¨è™Ÿ (1-5)")
    parser.add_argument("-u", "--api_url", default="http://127.0.0.1:5001", help="Persona API ç¶²å€")
    parser.add_argument("-e", "--eval_mode", action="store_true", default=False, help="åŸ·è¡Œè©•ä¼°æ¨¡å¼")
    
    args = parser.parse_args()
    
    from datetime import datetime
    start_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"ğŸ•’ é–‹å§‹æ™‚é–“: {start_time}")

    # å»ºç«‹ä¸¦åŸ·è¡Œ API åŸ·è¡Œå™¨
    runner = PersonaAPIRunner(args.api_url, args.dataset, args.type, args.prompt)
    discussion_output = runner.run()
    
    end_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # if args.eval_mode and discussion_output:
    #     # æ•´åˆåŸæœ‰çš„è©•ä¼°ç³»çµ±
    #     evaluation_root = Path(__file__).parent.parent / 'Evaluation'
    #     sys.path.append(str(evaluation_root))
    #     from auto_grade_final import auto_grade
        
    #     # å‘¼å«è©•ä¼°
    #     eval_args = SimpleNamespace(
    #         version="4", 
    #         input_file=discussion_output,  # é€™è£¡å·²ç¶“æ˜¯æ­£ç¢ºçš„æª”æ¡ˆåç¨±
    #         type="sampling", 
    #         sample=3, 
    #         task=args.type, 
    #         output="y"
    #     )
    #     auto_grade(eval_args)
    #     print(f"ğŸ•’ çµæŸæ™‚é–“: {end_time}")
    #     print(f"Total Time: {start_time} to {end_time}")


if __name__ == "__main__":
    main()

