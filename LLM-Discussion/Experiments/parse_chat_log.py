#!/usr/bin/env python3
"""
ç¨ç«‹è…³æœ¬ï¼šå¾ chat_log.json è§£æå‡ºè©•ä¼°ç‰ˆæœ¬çš„ JSON æª”æ¡ˆ
ä½¿ç”¨æ–¹æ³•: python parse_chat_log.py -i input_chat_log.json -o output_eval.json -t AUT
"""

import argparse
import json
import re
from pathlib import Path

def extract_responses(content):
    """æå–å›æ‡‰å…§å®¹ - èˆ‡ persona_conversation.py ç›¸åŒçš„é‚è¼¯"""
    import re
    
    # ä½¿ç”¨æ­£è¦è¡¨é”å¼æ‰¾åˆ°æ‰€æœ‰ç·¨è™Ÿé …ç›®åŠå…¶å®Œæ•´å…§å®¹
    # åŒ¹é…æ ¼å¼å¦‚ï¼š1. **æ¨™é¡Œ**: æè¿°å…§å®¹...
    pattern = r'(\d+\.\s*\*\*[^*]+\*\*:?\s*(?:[^\n]+(?:\n(?!\d+\.\s*\*\*)[^\n]*)*)?)'
    matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
    
    responses = []
    for match in matches:
        # æ¸…ç†ä¸¦æ ¼å¼åŒ–æ¯å€‹é …ç›®
        clean_response = match.strip()
        # ç§»é™¤é–‹é ­çš„æ•¸å­—å’Œé»è™Ÿï¼Œä½†ä¿ç•™å®Œæ•´å…§å®¹
        clean_response = re.sub(r'^\d+\.\s*', '', clean_response)
        if clean_response:
            responses.append(clean_response)
    
    # å¦‚æœæ­£è¦è¡¨é”å¼æ²’æœ‰åŒ¹é…åˆ°ï¼Œå›é€€åˆ°åŸå§‹é‚è¼¯
    if not responses:
        lines = content.split('\n')
        current_item = ""
        
        for line in lines:
            line = line.strip()
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯æ–°é …ç›®çš„é–‹å§‹
            if line and (line.startswith('-') or line.startswith('â€¢') or 
                        any(line.startswith(f"{i}.") for i in range(1, 20))):
                # å¦‚æœæœ‰å‰ä¸€å€‹é …ç›®ï¼Œå…ˆå„²å­˜
                if current_item:
                    clean_response = current_item.lstrip('-â€¢0123456789. ').strip()
                    if clean_response:
                        responses.append(clean_response)
                
                # é–‹å§‹æ–°é …ç›®
                current_item = line
            elif current_item and line:
                # ç¹¼çºŒç•¶å‰é …ç›®çš„å…§å®¹
                current_item += "\n" + line
        
        # è™•ç†æœ€å¾Œä¸€å€‹é …ç›®
        if current_item:
            clean_response = current_item.lstrip('-â€¢0123456789. ').strip()
            if clean_response:
                responses.append(clean_response)
    
    return responses

def parse_chat_log_to_eval_format(chat_log_data, task_type):
    """å°‡ chat_log æ ¼å¼è½‰æ›ç‚ºè©•ä¼°æ ¼å¼"""
    eval_results = []
    
    for item_key, conversations in chat_log_data.items():
        if "PersonaAPI" in conversations:
            conversation = conversations["PersonaAPI"]
            
            # æ‰¾åˆ°åŠ©æ‰‹çš„å›æ‡‰
            assistant_content = None
            for msg in conversation:
                if msg.get("role") == "assistant":
                    assistant_content = msg.get("content", "")
                    break
            
            if assistant_content:
                # æå–å›æ‡‰
                extracted_responses = extract_responses(assistant_content)
                
                # æ ¹æ“šä»»å‹™é¡å‹å»ºç«‹ä¸åŒçš„çµæ§‹
                if task_type == "AUT":
                    eval_results.append({
                        "item": item_key,
                        "uses": extracted_responses,
                        "Agent": "PersonaAPI"
                    })
                elif task_type == "Scientific":
                    eval_results.append({
                        "question": item_key,
                        "answer": extracted_responses,
                        "Agent": "PersonaAPI"
                    })
                elif task_type in ["Instances", "Similarities"]:
                    eval_results.append({
                        "question": item_key,
                        "answer": extracted_responses,
                        "Agent": "PersonaAPI"
                    })
                else:
                    print(f"âŒ ä¸æ”¯æ´çš„ä»»å‹™é¡å‹: {task_type}")
                    continue
            else:
                # å¦‚æœæ²’æœ‰æ‰¾åˆ°åŠ©æ‰‹å›æ‡‰ï¼Œå»ºç«‹ç©ºé …ç›®
                if task_type == "AUT":
                    eval_results.append({
                        "item": item_key,
                        "uses": [],
                        "Agent": "PersonaAPI"
                    })
                elif task_type == "Scientific":
                    eval_results.append({
                        "question": item_key,
                        "answer": [],
                        "Agent": "PersonaAPI"
                    })
                elif task_type in ["Instances", "Similarities"]:
                    eval_results.append({
                        "question": item_key,
                        "answer": [],
                        "Agent": "PersonaAPI"
                    })
    
    return eval_results

def auto_detect_task_type(chat_log_data):
    """è‡ªå‹•åµæ¸¬ä»»å‹™é¡å‹"""
    # æª¢æŸ¥ç¬¬ä¸€å€‹å°è©±å…§å®¹ä¾†çŒœæ¸¬ä»»å‹™é¡å‹
    for item_key, conversations in chat_log_data.items():
        if "PersonaAPI" in conversations:
            conversation = conversations["PersonaAPI"]
            for msg in conversation:
                if msg.get("role") == "user":
                    content = msg.get("content", "").lower()
                    if "uses for" in content or "ç”¨é€”" in content:
                        return "AUT"
                    elif "scientific" in content or "ç§‘å­¸" in content:
                        return "Scientific"
                    elif "instances" in content or "examples" in content or "ç¯„ä¾‹" in content:
                        return "Instances"
                    elif "similarities" in content or "ç›¸ä¼¼" in content:
                        return "Similarities"
            break
    
    # é è¨­è¿”å› AUT
    return "AUT"

def generate_output_filename(input_filename, task_type):
    """æ ¹æ“šè¼¸å…¥æª”åç”¢ç”Ÿè¼¸å‡ºæª”å"""
    input_path = Path(input_filename)
    
    # ç§»é™¤ _chat_log å¾Œç¶´
    base_name = input_path.stem
    if base_name.endswith("_chat_log"):
        base_name = base_name[:-9]  # ç§»é™¤ "_chat_log"
    
    # å¦‚æœæª”åä¸æ˜¯æ¨™æº–æ ¼å¼ï¼Œå˜—è©¦å»ºç«‹æ¨™æº–æ ¼å¼
    if not base_name.startswith(task_type):
        base_name = f"{task_type}_{base_name}"
    
    return f"{base_name}.json"

def main():
    parser = argparse.ArgumentParser(description="å¾ chat_log.json è§£æå‡ºè©•ä¼°ç‰ˆæœ¬çš„ JSON æª”æ¡ˆ")
    # parser.add_argument("-i", "--input", required=True, help="è¼¸å…¥çš„ chat_log.json æª”æ¡ˆè·¯å¾‘")
    # parser.add_argument("-o", "--output", help="è¼¸å‡ºçš„è©•ä¼° JSON æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼Œæœƒè‡ªå‹•ç”¢ç”Ÿï¼‰")
    parser.add_argument("-t", "--task", choices=["AUT", "Scientific", "Instances", "Similarities"], 
                       help="ä»»å‹™é¡å‹ï¼ˆå¯é¸ï¼Œæœƒè‡ªå‹•åµæ¸¬ï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="åªé¡¯ç¤ºè§£æçµæœï¼Œä¸å¯«å…¥æª”æ¡ˆ")
    
    args = parser.parse_args()
    
    
    # æª¢æŸ¥è¼¸å…¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    # input_path = Path(args.input)
    input_path = Path("../Results/AUT/Output/persona_agent/AUT_persona_api_0913-1905_100_chat_log.json")
    output_path = Path("../Results/AUT/Output/persona_agent/AUT_persona_api_0913-1905_100.json")
    
    if not input_path.exists():
        print(f"âŒ è¼¸å…¥æª”æ¡ˆä¸å­˜åœ¨: {args.input}")
        return 1
    
    # è¼‰å…¥ chat_log è³‡æ–™
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            chat_log_data = json.load(f)
        print(f"âœ… æˆåŠŸè¼‰å…¥ chat_log: {input_path}")
    except Exception as e:
        print(f"âŒ è¼‰å…¥æª”æ¡ˆå¤±æ•—: {e}")
        return 1
    
    # ç¢ºå®šä»»å‹™é¡å‹
    task_type = args.task
    if not task_type:
        task_type = auto_detect_task_type(chat_log_data)
        print(f"ğŸ” è‡ªå‹•åµæ¸¬ä»»å‹™é¡å‹: {task_type}")
    else:
        print(f"ğŸ“‹ ä½¿ç”¨æŒ‡å®šä»»å‹™é¡å‹: {task_type}")
    
    # è§£æè³‡æ–™
    eval_results = parse_chat_log_to_eval_format(chat_log_data, task_type)
    
    print(f"ğŸ“Š è§£æçµæœ:")
    print(f"  - é …ç›®ç¸½æ•¸: {len(eval_results)}")
    
    # çµ±è¨ˆæœ‰æ•ˆé …ç›®
    valid_items = 0
    empty_items = 0
    
    for item in eval_results:
        if task_type == "AUT":
            if item.get("uses"):
                valid_items += 1
            else:
                empty_items += 1
        else:
            if item.get("answer"):
                valid_items += 1
            else:
                empty_items += 1
    
    print(f"  - æœ‰æ•ˆé …ç›®: {valid_items}")
    print(f"  - ç©ºç™½é …ç›®: {empty_items}")
    
    # é¡¯ç¤ºå‰å¹¾å€‹é …ç›®çš„ç¯„ä¾‹
    print(f"\nğŸ“‹ å‰ 3 å€‹é …ç›®ç¯„ä¾‹:")
    for i, item in enumerate(eval_results[:3]):
        if task_type == "AUT":
            item_name = item.get("item", "Unknown")
            uses_count = len(item.get("uses", []))
            print(f"  {i+1}. {item_name}: {uses_count} uses")
            # é¡¯ç¤ºç¬¬ä¸€å€‹ use çš„é–‹é ­
            if item.get("uses"):
                first_use = item["uses"][0]
                preview = first_use[:50] + "..." if len(first_use) > 50 else first_use
                print(f"     â””â”€ {preview}")
        else:
            question = item.get("question", "Unknown")
            answer_count = len(item.get("answer", []))
            print(f"  {i+1}. {question}: {answer_count} answers")
    
    # å¦‚æœæ˜¯ dry-runï¼Œåªé¡¯ç¤ºçµæœä¸å¯«å…¥æª”æ¡ˆ
    if args.dry_run:
        print(f"\nğŸ” Dry-run æ¨¡å¼ï¼Œä¸å¯«å…¥æª”æ¡ˆ")
        print(f"å®Œæ•´è³‡æ–™é è¦½:")
        print(json.dumps(eval_results[:2], indent=2, ensure_ascii=False))
        return 0
    
    # ç¢ºå®šè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    # if args.output:
    #     output_path = Path(args.output)
    # else:
    #     output_filename = generate_output_filename(args.input, task_type)
    #     output_path = input_path.parent / output_filename
    
    # å¯«å…¥æª”æ¡ˆ
    try:
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(eval_results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… è©•ä¼°æ ¼å¼æª”æ¡ˆå·²å„²å­˜: {output_path}")
        print(f"ğŸ“ æª”æ¡ˆå¤§å°: {output_path.stat().st_size} bytes")
        
        return 0
        
    except Exception as e:
        print(f"âŒ å¯«å…¥æª”æ¡ˆå¤±æ•—: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
