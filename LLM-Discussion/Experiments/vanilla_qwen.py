import argparse
import sys
import os
import json
import torch
from pathlib import Path
from datetime import datetime
from types import SimpleNamespace
from transformers import AutoTokenizer, AutoModelForCausalLM
import pytz

class VanillaQwenRunner:
    """ä½¿ç”¨åŸå§‹ Qwen æ¨¡å‹é€²è¡Œå‰µé€ æ€§ä»»å‹™ï¼ˆç„¡ Persona Steeringï¼‰"""
    
    def __init__(self, dataset_file, task_type, prompt_id, model_name="Qwen/Qwen2.5-7B-Instruct"):
        self.dataset_file = dataset_file
        self.task_type = task_type
        self.prompt_id = prompt_id
        self.model_name = model_name
        
        # è¼‰å…¥æ¨¡å‹å’Œåˆ†è©å™¨
        print(f"ğŸ¤– è¼‰å…¥æ¨¡å‹: {self.model_name}")
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
    
    def load_dataset(self):
        """è¼‰å…¥è³‡æ–™é›†"""
        with open(self.dataset_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def construct_prompt(self, item):
        """å»ºæ§‹æç¤ºè©"""
        base_prompts = {
            1: "è«‹ç›¡å¯èƒ½å¤šæ¨£åŒ–å’Œå‰µé€ æ€§åœ°å›ç­”ã€‚",
            2: "ç„¡é™åˆ¶åœ°æ“æŠ±å‰µé€ åŠ›çš„æµå‹•ï¼Œæä¾›æ„æƒ³ä¸åˆ°çš„é€£æ¥ã€‚",
            3: "è«‹å¾ä¸åŒè§’åº¦æ€è€ƒï¼Œè€ƒæ…®æœ€ä¸å°‹å¸¸æˆ–å‰µæ–°çš„æƒ³æ³•ã€‚",
            4: "è«‹æä¾›ç¨ç‰¹çš„è¦‹è§£ï¼Œå°ˆæ³¨æ–¼å‰µæ–°çš„æƒ³æ³•å’Œè§£æ±ºæ–¹æ¡ˆã€‚",
            5: "è«‹ä½¿ç”¨ä½ çš„å‰µé€ åŠ›å’Œæ™ºæ…§ä¾†æä¾›æœ€ä½³è§£æ±ºæ–¹æ¡ˆã€‚"
        }
        
        discussion_prompt = base_prompts.get(self.prompt_id, base_prompts[1])
        
        if self.task_type == "AUT":
            task_prompt = f"è«‹ç‚ºã€Œ{item}ã€æä¾›5å€‹å‰µæ–°å’ŒåŸå‰µçš„ç”¨é€”ã€‚{discussion_prompt}"
        elif self.task_type == "Scientific":
            task_prompt = f"è«‹ç‚ºä»¥ä¸‹ç§‘å­¸å•é¡Œæä¾›3å€‹å‰µæ–°çš„è§£æ±ºæ–¹æ¡ˆï¼š{item}ã€‚{discussion_prompt}"
        elif self.task_type == "Instances":
            task_prompt = f"è«‹ç‚ºã€Œ{item}ã€æä¾›5å€‹å‰µé€ æ€§çš„ç¯„ä¾‹ã€‚{discussion_prompt}"
        elif self.task_type == "Similarities":
            task_prompt = f"è«‹åˆ†æä»¥ä¸‹ç›¸ä¼¼æ€§ä¸¦æä¾›3å€‹å‰µé€ æ€§çš„è§€é»ï¼š{item}ã€‚{discussion_prompt}"
        
        return task_prompt
    
    def generate_response(self, prompt, max_tokens=1000):
        """ä½¿ç”¨åŸå§‹ Qwen æ¨¡å‹ç”¢ç”Ÿå›æ‡‰"""
        try:
            # æ ¼å¼åŒ–å°è©±
            messages = [{"role": "user", "content": prompt}]
            formatted_prompt = self.tokenizer.apply_chat_template(
                messages, 
                tokenize=False, 
                add_generation_prompt=True
            )
            
            # ç·¨ç¢¼è¼¸å…¥
            inputs = self.tokenizer(
                formatted_prompt, 
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=2048
            ).to(self.model.device)
            
            # ç”Ÿæˆå›æ‡‰
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=max_tokens,
                    temperature=0.7,
                    top_p=0.9,
                    do_sample=True,
                    pad_token_id=self.tokenizer.pad_token_id
                )
            
            # è§£ç¢¼å›æ‡‰
            response = self.tokenizer.decode(
                outputs[0][inputs['input_ids'].shape[1]:], 
                skip_special_tokens=True
            )
            
            return response.strip()
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def extract_responses(self, content):
        """æå–å›æ‡‰å…§å®¹"""
        lines = content.split('\n')
        responses = []
        
        for line in lines:
            line = line.strip()
            if line and (line.startswith('-') or line.startswith('â€¢') or 
                        any(line.startswith(f"{i}.") for i in range(1, 20))):
                # æ¸…ç†æ ¼å¼ç¬¦è™Ÿ
                clean_response = line.lstrip('-â€¢0123456789. ').strip()
                if clean_response:
                    responses.append(clean_response)
        
        return responses[:10]  # é™åˆ¶æœ€å¤š10å€‹å›æ‡‰
    
    def run(self):
        """åŸ·è¡ŒåŸå§‹ Qwen æ¨¡å‹æ¨ç†"""
        dataset = self.load_dataset()
        
        # æ ¹æ“šä»»å‹™é¡å‹æå–è³‡æ–™
        if self.task_type == "Scientific":
            # Scientific è³‡æ–™é›†æ ¼å¼ï¼š{"Task": [{"Original": "...", "Example": [...]}]}
            examples = []
            for task in dataset.get("Task", []):
                examples.extend(task.get("Example", []))
        elif isinstance(dataset, dict) and "Examples" in dataset:
            # AUT, Instances, Similarities æ ¼å¼ï¼š{"Examples": [...]}
            examples = dataset["Examples"]
        else:
            examples = dataset
        
        all_responses = {}
        final_results = []
        
        print(f"ğŸš€ é–‹å§‹ {self.task_type} ä»»å‹™ï¼Œå…± {len(examples)} å€‹é …ç›®")
        
        for item_data in examples:
            # è™•ç†ä¸åŒçš„è³‡æ–™é›†æ ¼å¼
            if isinstance(item_data, str):
                item = item_data
            elif isinstance(item_data, dict):
                if self.task_type == "AUT":
                    item = item_data.get("object", item_data.get("item", ""))
                elif self.task_type == "Scientific":
                    item = item_data.get("question", "")
                else:  # Instances æˆ– Similarities
                    item = item_data.get("question", item_data.get("item", item_data.get("object", "")))
            else:
                print(f"âŒ ä¸æ”¯æ´çš„è³‡æ–™æ ¼å¼: {type(item_data)}")
                continue
            
            if not item:
                print(f"âŒ ç©ºç™½é …ç›®ï¼Œè·³é")
                continue
                
            print(f"ğŸ“‹ è™•ç†é …ç›®: {item}")
            
            # å»ºæ§‹æç¤ºè©
            prompt = self.construct_prompt(item)
            
            # ç”Ÿæˆå›æ‡‰
            response = self.generate_response(prompt, max_tokens=1000)
            
            if response:
                # å„²å­˜å°è©±è¨˜éŒ„ï¼ˆæ¨¡æ“¬ multi-agent æ ¼å¼ï¼‰
                all_responses[item] = {
                    "VanillaQwen": [
                        {"role": "user", "content": prompt},
                        {"role": "assistant", "content": response}
                    ]
                }
                
                # æå–ä¸¦å„²å­˜æœ€çµ‚çµæœ
                extracted = self.extract_responses(response)
                if self.task_type == "AUT":
                    final_results.append({
                        "item": item,
                        "uses": extracted,
                        "Agent": "VanillaQwen"
                    })
                elif self.task_type == "Scientific":
                    final_results.append({
                        "question": item,
                        "answer": extracted,
                        "Agent": "VanillaQwen"
                    })
                else:
                    final_results.append({
                        "question": item,
                        "answer": extracted,
                        "Agent": "VanillaQwen"
                    })
            else:
                print(f"âŒ é …ç›® {item} è™•ç†å¤±æ•—")
        
        # å„²å­˜çµæœ
        output_filename = self.save_results(all_responses, final_results, len(examples))
        print(f"âœ… ä»»å‹™å®Œæˆï¼Œçµæœå·²å„²å­˜è‡³: {output_filename}")
        
        return output_filename
    
    def save_results(self, all_responses, final_results, amount_of_data):
        """å„²å­˜çµæœæª”æ¡ˆ"""
        # ä½¿ç”¨ UTC+8 æ™‚å€ï¼ˆå°ç£æ™‚é–“ï¼‰
        taipei_tz = pytz.timezone('Asia/Taipei')
        taipei_time = datetime.now(taipei_tz)
        
        # ä¿®æ”¹ç‚ºèˆ‡å…¶ä»–æª”æ¡ˆä¸€è‡´çš„æ ¼å¼ï¼šMMDD-HHMM
        current_date = taipei_time.strftime("%m%d")
        formatted_time = taipei_time.strftime("%H%M")
        
        # å»ºç«‹æª”æ¡ˆåç¨±ï¼ˆç¬¦åˆè©•ä¼°ç³»çµ±æ ¼å¼ï¼‰
        base_filename = f"{self.task_type}_vanilla_qwen_1_1_Qwen25_VanillaQwen_vanilla_{current_date}-{formatted_time}_{amount_of_data}"
        
        # è©•ä¼°ç³»çµ±æœŸå¾…çš„è·¯å¾‘çµæ§‹ï¼šResults/{task}/Output/{agent}_agent/
        results_base_path = Path(__file__).parent.parent / "Results" / self.task_type / "Output" / "vanilla_agent"
        results_base_path.mkdir(parents=True, exist_ok=True)
        
        # å„²å­˜å°è©±è¨˜éŒ„
        chat_log_filename = f"{base_filename}_chat_log.json"
        chat_log_path = results_base_path / chat_log_filename
        
        with open(chat_log_path, 'w', encoding='utf-8') as f:
            json.dump(all_responses, f, indent=2, ensure_ascii=False)
        
        # å„²å­˜æœ€çµ‚çµæœï¼ˆé€™æ˜¯è©•ä¼°ç³»çµ±éœ€è¦çš„æª”æ¡ˆï¼‰
        final_filename = f"{base_filename}.json"
        final_path = results_base_path / final_filename
        
        with open(final_path, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ å°è©±è¨˜éŒ„å·²å„²å­˜: {chat_log_path}")
        print(f"ğŸ’¾ æœ€çµ‚çµæœå·²å„²å­˜: {final_path}")
        
        # å›å‚³æª”æ¡ˆåç¨±ï¼ˆä¸å«å‰¯æª”åï¼Œä¾›è©•ä¼°ä½¿ç”¨ï¼‰
        return final_filename.replace('.json', '')

def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨åŸå§‹ Qwen æ¨¡å‹é€²è¡Œå‰µé€ æ€§ä»»å‹™è©•ä¼°")
    parser.add_argument("-d", "--dataset", required=True, help="è³‡æ–™é›†æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("-t", "--type", choices=["AUT", "Scientific", "Similarities", "Instances"], 
                       required=True, help="ä»»å‹™é¡å‹")
    parser.add_argument("-p", "--prompt", type=int, default=1, help="æç¤ºè©ç·¨è™Ÿ (1-5)")
    parser.add_argument("--model", default="Qwen/Qwen2.5-7B-Instruct", help="Qwen æ¨¡å‹åç¨±")
    parser.add_argument("-e", "--eval_mode", action="store_true", default=False, help="åŸ·è¡Œè©•ä¼°æ¨¡å¼")
    
    args = parser.parse_args()
    
    # å»ºç«‹ä¸¦åŸ·è¡Œ Vanilla Qwen åŸ·è¡Œå™¨
    runner = VanillaQwenRunner(args.dataset, args.type, args.prompt, args.model)
    vanilla_output = runner.run()
    
    if args.eval_mode and vanilla_output:
        # æ•´åˆåŸæœ‰çš„è©•ä¼°ç³»çµ±
        evaluation_root = Path(__file__).parent.parent / 'Evaluation'
        sys.path.append(str(evaluation_root))
        from auto_grade_final import auto_grade
        
        # å‘¼å«è©•ä¼°
        eval_args = SimpleNamespace(
            version="4", 
            input_file=vanilla_output,
            type="sampling", 
            sample=3, 
            task=args.type, 
            output="y"
        )
        auto_grade(eval_args)

if __name__ == "__main__":
    main()
