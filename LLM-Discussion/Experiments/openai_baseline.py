import argparse
import sys
import os
import json
import openai
from pathlib import Path
from datetime import datetime
from types import SimpleNamespace
import pytz

class OpenAIBaselineRunner:
    """ä½¿ç”¨ Pure OpenAI API é€²è¡Œå‰µé€ æ€§ä»»å‹™çš„åŸºç·šæ¨¡å‹"""
    
    def __init__(self, dataset_file, task_type, prompt_id, model_name="gpt-4o-mini"):
        self.dataset_file = dataset_file
        self.task_type = task_type
        self.prompt_id = prompt_id
        self.model_name = model_name
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
        self.client = openai.OpenAI(
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
    def test_api_connection(self):
        """æ¸¬è©¦ OpenAI API é€£ç·š"""
        try:
            response = self.client.models.list()
            print(f"âœ… OpenAI API é€£ç·šæˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ OpenAI API é€£ç·šéŒ¯èª¤: {e}")
            return False
    
    def call_openai_api(self, prompt, max_tokens=1000):
        """å‘¼å« OpenAI API"""
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                top_p=0.9
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"âŒ OpenAI API è«‹æ±‚éŒ¯èª¤: {e}")
            return None
    
    def load_dataset(self):
        """è¼‰å…¥è³‡æ–™é›†"""
        with open(self.dataset_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def construct_prompt(self, item):
        """å»ºæ§‹æç¤ºè©"""
        base_prompts = {
            1: "è«‹ç›¡å¯èƒ½å¤šæ¨£åŒ–å’Œå‰µé€ æ€§åœ°å›ç­”ã€‚",
            2: "ç„¡é™åˆ¶åœ°æ“æŠ±å‰µé€ åŠ›çš„æµå‹•ï¼Œæä¾›æ„æƒ³ä¸åˆ°çš„é€£æ¥ã€‚",
            3: "è«‹å¾ä¸åŒè§’åº¦æ€è€ƒï¼Œè€ƒæ…®æœ€ä¸å°‹å¸¸æˆ–å‰µæ–°çš„æƒ³æ³•ã€‚",
            4: "è«‹æä¾›ç¨ç‰¹çš„è¦‹è§£ï¼Œå°ˆæ³¨æ–¼å‰µæ–°çš„æƒ³æ³•å’Œè§£æ±ºæ–¹æ¡ˆã€‚",
            5: "è«‹ä½¿ç”¨ä½ çš„å‰µé€ åŠ›å’Œæ™ºæ…§ä¾†æä¾›æœ€ä½³è§£æ±ºæ–¹æ¡ˆã€‚"
        }
        
        discussion_prompt = base_prompts.get(self.prompt_id, base_prompts[1])
        
        if self.task_type == "AUT":
            task_prompt = f"è«‹ç‚ºã€Œ{item}ã€æä¾›5å€‹å‰µæ–°å’ŒåŸå‰µçš„ç”¨é€”ã€‚{discussion_prompt}"
        elif self.task_type == "Scientific":
            task_prompt = f"è«‹ç‚ºä»¥ä¸‹ç§‘å­¸å•é¡Œæä¾›3å€‹å‰µæ–°çš„è§£æ±ºæ–¹æ¡ˆï¼š{item}ã€‚{discussion_prompt}"
        elif self.task_type == "Instances":
            task_prompt = f"è«‹ç‚ºã€Œ{item}ã€æä¾›5å€‹å‰µé€ æ€§çš„ç¯„ä¾‹ã€‚{discussion_prompt}"
        elif self.task_type == "Similarities":
            task_prompt = f"è«‹åˆ†æä»¥ä¸‹ç›¸ä¼¼æ€§ä¸¦æä¾›3å€‹å‰µé€ æ€§çš„è§€é»ï¼š{item}ã€‚{discussion_prompt}"
        
        return task_prompt
    
    def extract_responses(self, content):
        """æå–å›æ‡‰å…§å®¹"""
        lines = content.split('\n')
        responses = []
        
        for line in lines:
            line = line.strip()
            if line and (line.startswith('-') or line.startswith('â€¢') or 
                        any(line.startswith(f"{i}.") for i in range(1, 20))):
                # æ¸…ç†æ ¼å¼ç¬¦è™Ÿ
                clean_response = line.lstrip('-â€¢0123456789. ').strip()
                if clean_response:
                    responses.append(clean_response)
        
        return responses[:10]  # é™åˆ¶æœ€å¤š10å€‹å›æ‡‰
    
    def run(self):
        """åŸ·è¡Œ OpenAI API å‘¼å«"""
        if not self.test_api_connection():
            return None
        
        dataset = self.load_dataset()
        
        # å¾è³‡æ–™é›†ä¸­æå– Examples
        if isinstance(dataset, dict) and "Examples" in dataset:
            examples = dataset["Examples"]
        else:
            examples = dataset
        
        all_responses = {}
        final_results = []
        
        print(f"ğŸš€ é–‹å§‹ {self.task_type} ä»»å‹™ï¼Œå…± {len(examples)} å€‹é …ç›®")
        
        for item_data in examples:
            # è™•ç†ä¸åŒçš„è³‡æ–™é›†æ ¼å¼
            if isinstance(item_data, str):
                item = item_data
            elif isinstance(item_data, dict):
                if self.task_type == "AUT":
                    item = item_data.get("object", item_data.get("item", ""))
                elif self.task_type == "Scientific":
                    item = item_data.get("question", "")
                else:  # Instances æˆ– Similarities
                    item = item_data.get("question", item_data.get("item", item_data.get("object", "")))
            else:
                print(f"âŒ ä¸æ”¯æ´çš„è³‡æ–™æ ¼å¼: {type(item_data)}")
                continue
            
            if not item:
                print(f"âŒ ç©ºç™½é …ç›®ï¼Œè·³é")
                continue
                
            print(f"ğŸ“‹ è™•ç†é …ç›®: {item}")
            
            # å»ºæ§‹æç¤ºè©
            prompt = self.construct_prompt(item)
            
            # å‘¼å« OpenAI API
            response = self.call_openai_api(prompt, max_tokens=1000)
            
            if response:
                # å„²å­˜å°è©±è¨˜éŒ„ï¼ˆæ¨¡æ“¬ multi-agent æ ¼å¼ï¼‰
                all_responses[item] = {
                    "OpenAI_Baseline": [
                        {"role": "user", "content": prompt},
                        {"role": "assistant", "content": response}
                    ]
                }
                
                # æå–ä¸¦å„²å­˜æœ€çµ‚çµæœ
                extracted = self.extract_responses(response)
                if self.task_type == "AUT":
                    final_results.append({
                        "item": item,
                        "uses": extracted,
                        "Agent": "OpenAI_Baseline"
                    })
                elif self.task_type == "Scientific":
                    final_results.append({
                        "question": item,
                        "answer": extracted,
                        "Agent": "OpenAI_Baseline"
                    })
                else:
                    final_results.append({
                        "question": item,
                        "answer": extracted,
                        "Agent": "OpenAI_Baseline"
                    })
            else:
                print(f"âŒ é …ç›® {item} è™•ç†å¤±æ•—")
        
        # å„²å­˜çµæœ
        output_filename = self.save_results(all_responses, final_results, len(examples))
        print(f"âœ… ä»»å‹™å®Œæˆï¼Œçµæœå·²å„²å­˜è‡³: {output_filename}")
        
        return output_filename
    
    def save_results(self, all_responses, final_results, amount_of_data):
        """å„²å­˜çµæœæª”æ¡ˆ"""
        # ä½¿ç”¨ UTC+8 æ™‚å€ï¼ˆå°ç£æ™‚é–“ï¼‰
        taipei_tz = pytz.timezone('Asia/Taipei')
        taipei_time = datetime.now(taipei_tz)
        
        # ä¿®æ”¹ç‚ºèˆ‡å…¶ä»–æª”æ¡ˆä¸€è‡´çš„æ ¼å¼ï¼šMMDD-HHMM
        current_date = taipei_time.strftime("%m%d")
        formatted_time = taipei_time.strftime("%H%M")
        
        # å»ºç«‹æª”æ¡ˆåç¨±
        model_name = self.model_name.replace("-", "_").replace(".", "_")
        base_filename = f"{self.task_type}_openai_baseline_1_1_{model_name}_OpenAI_baseline_{current_date}-{formatted_time}_{amount_of_data}"
        
        # ä¿®æ­£ï¼šä½¿ç”¨ openai_agent è€Œä¸æ˜¯ openai_baseline_agent
        results_base_path = Path(__file__).parent.parent / "Results" / self.task_type / "Output" / "openai_agent"
        results_base_path.mkdir(parents=True, exist_ok=True)
        
        # å„²å­˜å°è©±è¨˜éŒ„
        chat_log_filename = f"{base_filename}_chat_log.json"
        chat_log_path = results_base_path / chat_log_filename
        
        with open(chat_log_path, 'w', encoding='utf-8') as f:
            json.dump(all_responses, f, indent=2, ensure_ascii=False)
        
        # å„²å­˜æœ€çµ‚çµæœ
        final_filename = f"{base_filename}.json"
        final_path = results_base_path / final_filename
        
        with open(final_path, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ å°è©±è¨˜éŒ„å·²å„²å­˜: {chat_log_path}")
        print(f"ğŸ’¾ æœ€çµ‚çµæœå·²å„²å­˜: {final_path}")
        
        return final_filename.replace('.json', '')

def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ Pure OpenAI API é€²è¡Œå‰µé€ æ€§ä»»å‹™è©•ä¼°")
    parser.add_argument("-d", "--dataset", required=True, help="è³‡æ–™é›†æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("-t", "--type", choices=["AUT", "Scientific", "Similarities", "Instances"], 
                       required=True, help="ä»»å‹™é¡å‹")
    parser.add_argument("-p", "--prompt", type=int, default=1, help="æç¤ºè©ç·¨è™Ÿ (1-5)")
    parser.add_argument("--model", default="gpt-4o-mini", help="OpenAI æ¨¡å‹åç¨±")
    parser.add_argument("-e", "--eval_mode", action="store_true", default=False, help="åŸ·è¡Œè©•ä¼°æ¨¡å¼")
    
    args = parser.parse_args()
    
    # å»ºç«‹ä¸¦åŸ·è¡Œ OpenAI åŸºç·šåŸ·è¡Œå™¨
    runner = OpenAIBaselineRunner(args.dataset, args.type, args.prompt, args.model)
    baseline_output = runner.run()
    
    if args.eval_mode and baseline_output:
        # æ•´åˆåŸæœ‰çš„è©•ä¼°ç³»çµ±
        evaluation_root = Path(__file__).parent.parent / 'Evaluation'
        sys.path.append(str(evaluation_root))
        from auto_grade_final import auto_grade
        
        # å‘¼å«è©•ä¼°
        eval_args = SimpleNamespace(
            version="4", 
            input_file=baseline_output,
            type="sampling", 
            sample=3, 
            task=args.type, 
            output="y"
        )
        auto_grade(eval_args)

if __name__ == "__main__":
    main()
