#!/usr/bin/env python3
"""
CSV Token Counter
è¨ˆç®— CSV æª”æ¡ˆä¸­ prompt å’Œ answer æ¬„ä½çš„ tokens
prompt = input tokens, answer = output tokens
"""

import pandas as pd
import tiktoken
import argparse
import sys
import os
from typing import Dict, Any

class CSVTokenCounter:
    def __init__(self, model: str = "gpt-4"):
        """åˆå§‹åŒ– token è¨ˆç®—å™¨"""
        try:
            self.encoding = tiktoken.encoding_for_model(model)
            self.model = model
        except KeyError:
            print(f"âš ï¸  æ¨¡å‹ {model} ä¸æ”¯æ´ï¼Œä½¿ç”¨ cl100k_base encoding")
            self.encoding = tiktoken.get_encoding("cl100k_base")
            self.model = "cl100k_base"
    
    def count_tokens(self, text: str) -> int:
        """è¨ˆç®—æ–‡å­—çš„ token æ•¸é‡"""
        if not text or pd.isna(text):
            return 0
        return len(self.encoding.encode(str(text)))
    
    def process_csv(self, csv_path: str) -> Dict[str, Any]:
        """è™•ç† CSV æª”æ¡ˆä¸¦è¨ˆç®— tokens"""
        try:
            # è®€å– CSV
            df = pd.read_csv(csv_path)
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            if 'prompt' not in df.columns or 'answer' not in df.columns:
                raise ValueError(f"CSV æª”æ¡ˆå¿…é ˆåŒ…å« 'prompt' å’Œ 'answer' æ¬„ä½ã€‚å¯ç”¨æ¬„ä½: {df.columns.tolist()}")
            
            # è¨ˆç®—æ¯è¡Œçš„ tokens
            df['input_tokens'] = df['prompt'].apply(self.count_tokens)
            df['output_tokens'] = df['answer'].apply(self.count_tokens)
            df['total_tokens'] = df['input_tokens'] + df['output_tokens']
            
            # çµ±è¨ˆçµæœ
            stats = {
                'file': os.path.basename(csv_path),
                'model': self.model,
                'total_rows': len(df),
                'valid_rows': len(df.dropna(subset=['prompt', 'answer'])),
                'total_input_tokens': df['input_tokens'].sum(),
                'total_output_tokens': df['output_tokens'].sum(),
                'total_tokens': df['total_tokens'].sum(),
                'avg_input_tokens': df['input_tokens'].mean(),
                'avg_output_tokens': df['output_tokens'].mean(),
                'avg_total_tokens': df['total_tokens'].mean(),
                'input_ratio': (df['input_tokens'].sum() / df['total_tokens'].sum() * 100) if df['total_tokens'].sum() > 0 else 0,
                'output_ratio': (df['output_tokens'].sum() / df['total_tokens'].sum() * 100) if df['total_tokens'].sum() > 0 else 0,
                'detailed_data': df[['question', 'prompt', 'answer', 'input_tokens', 'output_tokens', 'total_tokens']].to_dict('records') if 'question' in df.columns else df[['prompt', 'answer', 'input_tokens', 'output_tokens', 'total_tokens']].to_dict('records')
            }
            
            return stats
            
        except Exception as e:
            raise Exception(f"è™•ç† CSV æª”æ¡ˆæ™‚å‡ºéŒ¯: {e}")
    
    def print_stats(self, stats: Dict[str, Any], show_details: bool = False):
        """å°å‡ºçµ±è¨ˆçµæœ"""
        print(f"\nğŸ“Š æª”æ¡ˆ {stats['file']} çš„ Token çµ±è¨ˆçµæœ")
        print("=" * 60)
        print(f"ğŸ”§ ä½¿ç”¨æ¨¡å‹: {stats['model']}")
        print(f"ğŸ“„ ç¸½è¡Œæ•¸: {stats['total_rows']:,}")
        print(f"âœ… æœ‰æ•ˆè¡Œæ•¸: {stats['valid_rows']:,}")
        print("-" * 60)
        print(f"ğŸ“¥ Input Tokens (prompt):  {stats['total_input_tokens']:,}")
        print(f"ğŸ“¤ Output Tokens (answer): {stats['total_output_tokens']:,}")
        print(f"ğŸ“Š Total Tokens:           {stats['total_tokens']:,}")
        print("-" * 60)
        print(f"ğŸ“Š Input æ¯”ä¾‹:   {stats['input_ratio']:.1f}%")
        print(f"ğŸ“Š Output æ¯”ä¾‹:  {stats['output_ratio']:.1f}%")
        print("-" * 60)
        print(f"ğŸ“Š å¹³å‡ Input Tokens:  {stats['avg_input_tokens']:.1f}")
        print(f"ğŸ“Š å¹³å‡ Output Tokens: {stats['avg_output_tokens']:.1f}")
        print(f"ğŸ“Š å¹³å‡ Total Tokens:  {stats['avg_total_tokens']:.1f}")
        print("=" * 60)
        
        if show_details:
            print("\nğŸ“‹ è©³ç´°è³‡æ–™:")
            for i, row in enumerate(stats['detailed_data'][:10], 1):  # åªé¡¯ç¤ºå‰10ç­†
                print(f"\n--- ç¬¬ {i} ç­† ---")
                if 'question' in row:
                    print(f"Question: {row['question'][:100]}...")
                print(f"Input tokens: {row['input_tokens']}")
                print(f"Output tokens: {row['output_tokens']}")
                print(f"Total tokens: {row['total_tokens']}")
            
            if len(stats['detailed_data']) > 10:
                print(f"\n... é‚„æœ‰ {len(stats['detailed_data']) - 10} ç­†è³‡æ–™")
    
    def save_results(self, stats: Dict[str, Any], output_path: str, format: str = "csv"):
        """å„²å­˜çµæœåˆ°æª”æ¡ˆ"""
        try:
            if format.lower() == "csv":
                # å»ºç«‹çµæœ DataFrame
                df_results = pd.DataFrame(stats['detailed_data'])
                df_results.to_csv(output_path, index=False, encoding='utf-8')
                print(f"âœ… è©³ç´°çµæœå·²å„²å­˜åˆ°: {output_path}")
                
            elif format.lower() == "json":
                import json
                # ç§»é™¤è©³ç´°è³‡æ–™ä»¥æ¸›å°‘æª”æ¡ˆå¤§å°
                summary_stats = {k: v for k, v in stats.items() if k != 'detailed_data'}
                summary_stats['sample_data'] = stats['detailed_data'][:5]  # åªä¿ç•™å‰5ç­†ç¯„ä¾‹
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(summary_stats, f, ensure_ascii=False, indent=2)
                print(f"âœ… çµ±è¨ˆçµæœå·²å„²å­˜åˆ°: {output_path}")
                
        except Exception as e:
            print(f"âŒ å„²å­˜çµæœæ™‚å‡ºéŒ¯: {e}")

def main():
    parser = argparse.ArgumentParser(description="è¨ˆç®— CSV æª”æ¡ˆä¸­ prompt å’Œ answer çš„ tokens")
    parser.add_argument("csv_file", help="è¦è™•ç†çš„ CSV æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--model", default="gpt-4o", help="ä½¿ç”¨çš„æ¨¡å‹ (é è¨­: gpt-4)")
    parser.add_argument("--output", help="è¼¸å‡ºæª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--format", choices=["csv", "json"], default="csv", help="è¼¸å‡ºæ ¼å¼ (é è¨­: csv)")
    parser.add_argument("--details", action="store_true", help="é¡¯ç¤ºè©³ç´°è³‡æ–™")
    
    args = parser.parse_args()
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.csv_file):
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {args.csv_file}")
        sys.exit(1)
    
    # å»ºç«‹è¨ˆç®—å™¨
    counter = CSVTokenCounter(args.model)
    
    try:
        # è™•ç† CSV æª”æ¡ˆ
        print(f"ğŸ”„ æ­£åœ¨è™•ç†æª”æ¡ˆ: {args.csv_file}")
        stats = counter.process_csv(args.csv_file)
        
        # é¡¯ç¤ºçµæœ
        counter.print_stats(stats, show_details=args.details)
        
        # å„²å­˜çµæœ
        if args.output:
            counter.save_results(stats, args.output, args.format)
        
    except Exception as e:
        print(f"âŒ è™•ç†éç¨‹ä¸­å‡ºéŒ¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
