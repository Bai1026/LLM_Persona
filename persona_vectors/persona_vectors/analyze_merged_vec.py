# tsne
from sklearn.manifold import TSNE
import umap

import torch
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os

# --- æ­¥é©Ÿ 1: è¨­å®šæ‚¨çš„æª”æ¡ˆè·¯å¾‘ ---
PERSONA_FILES = {
    'Analytical Thinker': './Llama-3.1-8B-Instruct/multi_role/analytical_thinker_response_avg_diff.pt',
    'Creative Professional': './Llama-3.1-8B-Instruct/multi_role/creative_professional_response_avg_diff.pt',
    'Environmentalist': './Llama-3.1-8B-Instruct/multi_role/environmentalist_response_avg_diff.pt',
    'Futurist': './Llama-3.1-8B-Instruct/multi_role/futurist_response_avg_diff.pt',

    # 'Social Entrepreneur': './Llama-3.1-8B-Instruct/multi_role/social_entrepreneur.pt',
    # 'Industry Insider': './Llama-3.1-8B-Instruct/multi_role/industry_insider_response_avg_diff.pt',
}

# --- æ–°å¢ï¼šå®šç¾©æ‚¨æƒ³è¦èåˆçš„ Persona ---
PERSONAS_TO_MERGE = ['Environmentalist', 'Creative Professional']


MODEL_NAME = "Llama-3.1-8B-Instruct" # å·²æ ¹æ“šæ‚¨çš„åœ–è¡¨æ›´æ–°
OUTPUT_DIR = "vector_analysis_charts"
os.makedirs(OUTPUT_DIR, exist_ok=True)


# --- æ­¥é©Ÿ 2: è¼‰å…¥å‘é‡ä¸¦è¨ˆç®—ç¯„æ•¸ ---
def load_and_calculate_norms(filepath):
    try:
        layer_vectors = torch.load(filepath, map_location='cpu')
        norms = torch.linalg.norm(layer_vectors, ord=2, dim=1)
        return norms.numpy(), layer_vectors
    except FileNotFoundError:
        print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {filepath}ï¼Œå°‡è·³éã€‚")
        return None, None

print("--- æ­£åœ¨è¼‰å…¥å‘é‡ä¸¦è¨ˆç®—æ¯ä¸€å±¤çš„ç¯„æ•¸ ---")
all_norms_data = []
all_layer_vectors = {} # å„²å­˜å®Œæ•´çš„ Tensors
for name, path in PERSONA_FILES.items():
    norms, layer_vectors = load_and_calculate_norms(path)
    if norms is not None:
        all_layer_vectors[name] = layer_vectors
        for layer_idx, norm_value in enumerate(norms):
            all_norms_data.append({
                "Persona": name,
                "Layer": layer_idx,
                "L2 Norm": norm_value
            })

df_norms = pd.DataFrame(all_norms_data)
print("ç¯„æ•¸è¨ˆç®—å®Œæˆã€‚")


# --- æ­¥é©Ÿ 3: è¦–è¦ºåŒ–åˆ†æ ---

# # åœ–è¡¨ä¸€ï¼šæ¯ä¸€å±¤çš„ç¯„æ•¸è®ŠåŒ–ï¼ˆæŠ˜ç·šåœ–ï¼‰
# print("\n--- æ­£åœ¨ç”Ÿæˆåœ–è¡¨ä¸€ï¼šå„å±¤ç¯„æ•¸è®ŠåŒ–æŠ˜ç·šåœ– ---")
# plt.style.use('seaborn-v0_8-whitegrid')
# plt.figure(figsize=(15, 8))
# # ... (æ­¤éƒ¨åˆ†ç¨‹å¼ç¢¼èˆ‡æ‚¨ç¾æœ‰ç‰ˆæœ¬ç›¸åŒï¼Œç‚ºç°¡æ½”çœç•¥)
# # sns.lineplot(...)
# # plt.savefig(...)
# print(f"åœ–è¡¨å·²å„²å­˜è‡³ {OUTPUT_DIR}/norm_across_layers.png")
# plt.close()

# # åœ–è¡¨äºŒï¼šå¹³å‡ç¯„æ•¸æ¯”è¼ƒï¼ˆæŸ±ç‹€åœ–ï¼‰
# print("\n--- æ­£åœ¨ç”Ÿæˆåœ–è¡¨äºŒï¼šå¹³å‡ç¯„æ•¸å¼·åº¦æŸ±ç‹€åœ– ---")
# df_avg_norms = df_norms.groupby('Persona')['L2 Norm'].mean().reset_index().sort_values(by='L2 Norm', ascending=False)
# plt.figure(figsize=(12, 7))
# # ... (æ­¤éƒ¨åˆ†ç¨‹å¼ç¢¼èˆ‡æ‚¨ç¾æœ‰ç‰ˆæœ¬ç›¸åŒï¼Œç‚ºç°¡æ½”çœç•¥)
# # sns.barplot(...)
# # plt.savefig(...)
# print(f"åœ–è¡¨å·²å„²å­˜è‡³ {OUTPUT_DIR}/average_norm_strength.png")
# plt.close()


# --- æ–°å¢åˆ†æä¸‰ï¼šè¿½è¹¤åˆä½µå¾Œ L2 Norm çš„è®ŠåŒ– ---
print("\n--- æ­£åœ¨åŸ·è¡Œåˆ†æä¸‰ï¼šåˆä½µå¾Œ L2 Norm è®ŠåŒ–è¿½è¹¤ ---")

# ç¯©é¸å‡ºè¦åˆä½µçš„å‘é‡
parent_vectors_tensors = [all_layer_vectors[name] for name in PERSONAS_TO_MERGE if name in all_layer_vectors]

if len(parent_vectors_tensors) == len(PERSONAS_TO_MERGE):
    # é€å±¤è¨ˆç®—
    num_layers = parent_vectors_tensors[0].shape[0]
    merge_analysis_results = []

    for layer_idx in range(num_layers):
        parent_norms_at_layer = [torch.linalg.norm(vec[layer_idx]).item() for vec in parent_vectors_tensors]
        
        # å–å¾—è©²å±¤çš„çˆ¶å‘é‡
        parent_vecs_at_layer = torch.stack([vec[layer_idx] for vec in parent_vectors_tensors])
        
        # è¨ˆç®—åˆä½µå¾Œçš„å‘é‡
        merged_vector_at_layer = torch.mean(parent_vecs_at_layer, dim=0)
        
        # è¨ˆç®—åˆä½µå¾Œå‘é‡çš„ç¯„æ•¸
        merged_norm_at_layer = torch.linalg.norm(merged_vector_at_layer).item()
        
        # è¨ˆç®—çˆ¶å‘é‡ç¯„æ•¸çš„å¹³å‡å€¼
        avg_parent_norm_at_layer = np.mean(parent_norms_at_layer)
        
        # è¨ˆç®—ç¨€é‡‹/æ”¾å¤§æ¯”ä¾‹
        dilution_ratio = merged_norm_at_layer / avg_parent_norm_at_layer
        
        merge_analysis_results.append({
            "Layer": layer_idx,
            "Avg Parent Norm": avg_parent_norm_at_layer,
            "Merged Norm": merged_norm_at_layer,
            "Dilution Ratio": dilution_ratio
        })

    df_merge_analysis = pd.DataFrame(merge_analysis_results)
    
    # æ‰“å°ç¸½çµ
    avg_dilution = df_merge_analysis['Dilution Ratio'].mean()
    print("\nåˆä½µåˆ†æç¸½çµ:")
    print(f"åˆä½µçš„ Personas: {', '.join(PERSONAS_TO_MERGE)}")
    print(f"å¹³å‡çˆ¶å‘é‡ç¯„æ•¸: {df_merge_analysis['Avg Parent Norm'].mean():.4f}")
    print(f"å¹³å‡åˆä½µå¾Œç¯„æ•¸: {df_merge_analysis['Merged Norm'].mean():.4f}")
    print(f"å¹³å‡ç¨€é‡‹æ¯”ä¾‹: {avg_dilution:.4f} (è‹¥ < 1 è¡¨ç¤ºç¨€é‡‹, > 1 è¡¨ç¤ºæ”¾å¤§)")

    # ç¹ªè£½ç¨€é‡‹æ¯”ä¾‹åœ–
    plt.figure(figsize=(15, 7))
    sns.lineplot(data=df_merge_analysis, x='Layer', y='Dilution Ratio', marker='o')
    plt.axhline(y=1, color='r', linestyle='--', label='No Change (Ratio=1)')
    plt.title(f'Merged Vector Norm Dilution Ratio Across Layers', fontsize=18)
    plt.xlabel('Model Layer Index', fontsize=12)
    plt.ylabel('Merged Norm / Average Parent Norm', fontsize=12)
    plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, 'merge_dilution_ratio.png'))
    print(f"ç¨€é‡‹æ¯”ä¾‹åœ–å·²å„²å­˜è‡³ {OUTPUT_DIR}/merge_dilution_ratio.png")
    plt.close()

else:
    print("éŒ¯èª¤ï¼šç„¡æ³•æ‰¾åˆ°æ‰€æœ‰æŒ‡å®šçš„ Persona å‘é‡é€²è¡Œåˆä½µåˆ†æã€‚")

# # --- æ–°å¢åˆ†æå››ï¼št-SNE / UMAP å¯è¦–åŒ–å‘é‡åˆ†å¸ƒï¼ˆå« Layer æ·±æ·ºï¼‰ ---
from sklearn.manifold import TSNE
import umap

print("\n--- æ­£åœ¨åŸ·è¡Œåˆ†æå››ï¼št-SNE / UMAP å¯è¦–åŒ–å‘é‡åˆ†å¸ƒ ---")

# å°‡æ‰€æœ‰ persona vectors å±•å¹³ç‚º [num_layers, hidden_size]
vector_list = []
label_list = []

for persona_name, tensor in all_layer_vectors.items():
    for layer_idx in range(tensor.shape[0]):
        vector_list.append(tensor[layer_idx].numpy())
        label_list.append(persona_name)

# æ–°å¢åˆä½µå‘é‡
if len(parent_vectors_tensors) == len(PERSONAS_TO_MERGE):
    merged_vectors = []
    for layer_idx in range(num_layers):
        merged = torch.mean(torch.stack([vec[layer_idx] for vec in parent_vectors_tensors]), dim=0)
        merged_vectors.append(merged.numpy())
        label_list.append("Merged Persona")
    vector_list.extend(merged_vectors)

# é™ç¶­è™•ç†
print("æ­£åœ¨ä½¿ç”¨ UMAP å°‡å‘é‡é™ç¶­è‡³ 2D ...")
reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='cosine', random_state=42)
embedding = reducer.fit_transform(vector_list)  # shape: [total_vectors, 2]

# è¦–è¦ºåŒ–
plt.figure(figsize=(10, 8))
sns.scatterplot(x=embedding[:, 0], y=embedding[:, 1], hue=label_list, palette='Set2', s=60)
plt.title("UMAP Projection of Persona Vectors (All Layers + Merged)", fontsize=16)
plt.xlabel("Component 1")
plt.ylabel("Component 2")
plt.legend()
plt.tight_layout()
tsne_output_path = os.path.join(OUTPUT_DIR, 'umap_persona_projection.png')
plt.savefig(tsne_output_path)
plt.close()

print(f"âœ… UMAP åœ–å·²å„²å­˜è‡³ï¼š{tsne_output_path}")

# from sklearn.manifold import TSNE
# import umap

# print("\n--- æ­£åœ¨åŸ·è¡Œåˆ†æå››ï¼št-SNE / UMAP å¯è¦–åŒ–å‘é‡åˆ†å¸ƒï¼ˆå« Layer æ·±æ·ºï¼‰ ---")

# # æº–å‚™è³‡æ–™
# vector_list = []
# persona_labels = []
# layer_indices = []

# for persona_name, tensor in all_layer_vectors.items():
#     for layer_idx in range(tensor.shape[0]):
#         vector_list.append(tensor[layer_idx].numpy())
#         persona_labels.append(persona_name)
#         layer_indices.append(layer_idx)

# # åŠ ä¸Š Merged Persona
# if len(parent_vectors_tensors) == len(PERSONAS_TO_MERGE):
#     for layer_idx in range(num_layers):
#         merged = torch.mean(torch.stack([vec[layer_idx] for vec in parent_vectors_tensors]), dim=0)
#         vector_list.append(merged.numpy())
#         persona_labels.append("Merged Persona")
#         layer_indices.append(layer_idx)

# # é™ç¶­
# print("æ­£åœ¨ä½¿ç”¨ UMAP å°‡å‘é‡é™ç¶­è‡³ 2D ...")
# reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='cosine', random_state=42)
# embedding = reducer.fit_transform(vector_list)

# # åˆä½µæˆ DataFrame æ–¹ä¾¿ç•«åœ–
# df_plot = pd.DataFrame({
#     "x": embedding[:, 0],
#     "y": embedding[:, 1],
#     "Persona": persona_labels,
#     "Layer": layer_indices
# })

# # ç•«åœ–
# plt.figure(figsize=(11, 9))
# sns.scatterplot(
#     data=df_plot,
#     x="x", y="y",
#     hue="Layer",  # Layer æ§åˆ¶é¡è‰²æ·±æ·º
#     style="Persona",  # Persona æ§åˆ¶ marker å½¢ç‹€
#     palette="viridis",  # å¯æ›æˆ "coolwarm", "cividis", "Spectral" ç­‰
#     s=70
# )

# plt.title("UMAP Projection of Persona Vectors (Colored by Layer)", fontsize=16)
# plt.xlabel("Component 1")
# plt.ylabel("Component 2")
# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
# plt.tight_layout()

# output_path = os.path.join(OUTPUT_DIR, "umap_with_layer_shade.png")
# plt.savefig(output_path)
# plt.close()
# print(f"âœ… å« Layer æ·±æ·ºçš„åœ–å·²å„²å­˜è‡³ï¼š{output_path}")

# --- æ–°å¢åˆ†æäº”ï¼šè¨ˆç®— Merged Vector èˆ‡å„ Parent Vector çš„ Cosine Similarity ---
from sklearn.metrics.pairwise import cosine_similarity

print("\n--- æ­£åœ¨åŸ·è¡Œåˆ†æäº”ï¼šMerged Vector èˆ‡ Parent å‘é‡çš„ Cosine Similarity åˆ†æ ---")

cosine_results = []

if len(parent_vectors_tensors) == len(PERSONAS_TO_MERGE):
    for layer_idx in range(num_layers):
        # å–å¾—åˆä½µå¾Œå‘é‡
        merged_vector = torch.mean(
            torch.stack([vec[layer_idx] for vec in parent_vectors_tensors]), dim=0
        ).numpy().reshape(1, -1)  # shape: [1, hidden]

        # è¨ˆç®—æ¯å€‹ parent çš„ cosine similarity
        for i, persona_name in enumerate(PERSONAS_TO_MERGE):
            parent_vector = parent_vectors_tensors[i][layer_idx].numpy().reshape(1, -1)
            similarity = cosine_similarity(merged_vector, parent_vector)[0][0]

            cosine_results.append({
                "Layer": layer_idx,
                "Persona": persona_name,
                "Cosine Similarity": similarity
            })

    df_cosine = pd.DataFrame(cosine_results)

    # ğŸ”¥ è¦–è¦ºåŒ–
    plt.figure(figsize=(14, 7))
    sns.lineplot(data=df_cosine, x="Layer", y="Cosine Similarity", hue="Persona", marker="o")
    plt.title("Cosine Similarity: Merged Vector vs Each Parent Persona (per Layer)")
    plt.ylim(0, 1.0)
    plt.xlabel("Model Layer Index")
    plt.ylabel("Cosine Similarity")
    plt.legend(title="Parent Persona")
    plt.tight_layout()

    output_path = os.path.join(OUTPUT_DIR, "cosine_similarity_per_layer.png")
    plt.savefig(output_path)
    plt.close()

    print(f"âœ… Cosine Similarity åœ–å·²å„²å­˜è‡³ï¼š{output_path}")
else:
    print("âš ï¸ æ‰¾ä¸åˆ°æ‰€æœ‰æŒ‡å®šçš„ parent vectorsï¼Œç„¡æ³•é€²è¡Œ cosine similarity åˆ†æã€‚")
