#!/usr/bin/env python3
"""
ç°¡å–®çš„ Gemma-3-4b èŠå¤©è…³æœ¬
ç›´æ¥è¼¸å…¥å•é¡Œï¼Œæ¨¡å‹å›æ‡‰
"""

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

class SimpleGemma3Chat:
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
    def load_model(self):
        """è¼‰å…¥ Gemma-3-4b æ¨¡å‹"""
        model_name = "google/gemma-3-4b-it"
        print(f"ğŸ”„ è¼‰å…¥æ¨¡å‹: {model_name}")
        print(f"ğŸ“± ä½¿ç”¨è¨­å‚™: {self.device}")
        
        try:
            # è¼‰å…¥åˆ†è©å™¨
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # è¼‰å…¥æ¨¡å‹
            if self.device == "cuda":
                self.model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    torch_dtype=torch.bfloat16,
                    device_map="auto",
                    trust_remote_code=True
                )
            else:
                self.model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    torch_dtype=torch.float32,
                    device_map="cpu",
                    trust_remote_code=True
                )
            
            print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            return False
    
    def chat(self, user_input: str, max_new_tokens: int = 8096):
        """èˆ‡æ¨¡å‹å°è©±"""
        if self.model is None or self.tokenizer is None:
            print("âŒ æ¨¡å‹å°šæœªè¼‰å…¥")
            return None
        
        # æ§‹é€ å°è©±æ ¼å¼
        conversation = [
            {"role": "user", "content": user_input}
        ]
        
        try:
            # æ‡‰ç”¨èŠå¤©æ¨¡æ¿
            prompt = self.tokenizer.apply_chat_template(
                conversation,
                tokenize=False,
                add_generation_prompt=True
            )
            
            # ç·¨ç¢¼
            inputs = self.tokenizer(
                prompt,
                return_tensors="pt",
                truncation=True,
                max_length=2048
            )
            
            # ç§»å‹•åˆ°æ­£ç¢ºè¨­å‚™
            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}
            
            # ç”Ÿæˆå›æ‡‰
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.9,
                    repetition_penalty=1.1,
                    pad_token_id=self.tokenizer.pad_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )
            
            # è§£ç¢¼å›æ‡‰
            full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # æå–æ¨¡å‹å›æ‡‰éƒ¨åˆ†
            response = full_response[len(prompt):].strip()
            
            return response
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå›æ‡‰å¤±æ•—: {e}")
            return None

def main():
    """ä¸»å‡½å¼"""
    print("ğŸ¤– Gemma-3-4b ç°¡å–®èŠå¤©æ©Ÿå™¨äºº")
    print("è¼¸å…¥ 'quit' æˆ– 'exit' çµæŸå°è©±")
    print("=" * 50)
    
    # åˆå§‹åŒ–èŠå¤©æ©Ÿå™¨äºº
    chat_bot = SimpleGemma3Chat()
    
    # è¼‰å…¥æ¨¡å‹
    if not chat_bot.load_model():
        print("ç„¡æ³•è¼‰å…¥æ¨¡å‹ï¼Œç¨‹å¼çµæŸ")
        return
    
    print("\nâœ… æº–å‚™å°±ç·’ï¼é–‹å§‹å°è©±...")
    print("=" * 50)
    
    # å°è©±è¿´åœˆ
    while True:
        try:
            # ç²å–ä½¿ç”¨è€…è¼¸å…¥
            user_input = input("\nğŸ‘¤ æ‚¨: ").strip()
            
            # æª¢æŸ¥çµæŸæ¢ä»¶
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'çµæŸ']:
                print("ğŸ‘‹ å†è¦‹ï¼")
                break
            
            # è·³éç©ºè¼¸å…¥
            if not user_input:
                continue
            
            # ç”Ÿæˆå›æ‡‰
            print("ğŸ¤– æ€è€ƒä¸­...")
            response = chat_bot.chat(user_input)
            
            if response:
                print(f"ğŸ¤– Gemma: {response}")
            else:
                print("âŒ ç„¡æ³•ç”Ÿæˆå›æ‡‰ï¼Œè«‹é‡è©¦")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç¨‹å¼è¢«ä¸­æ–·ï¼Œå†è¦‹ï¼")
            break
        except Exception as e:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    main()
