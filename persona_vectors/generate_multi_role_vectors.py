import torch
import os
import pandas as pd
from typing import Dict, List, Tuple
from generate_vec import get_persona_effective, get_hidden_p_and_r_batched
from transformers import AutoModelForCausalLM, AutoTokenizer

class MultiRoleVectorGenerator:
    """å¤šè§’è‰²å‘é‡ç”¢ç”Ÿå™¨ - ä¿®æ­£ç‰ˆ"""
    
    def __init__(self, model_name: str, save_dir: str):
        self.model_name = model_name
        self.model_short_name = model_name.split('/')[-1]
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
        
        # è¼‰å…¥æ¨¡å‹
        print("ğŸ¤– è¼‰å…¥æ¨¡å‹...")
        self.model = AutoModelForCausalLM.from_pretrained(
            model_name, 
            device_map="auto",
            torch_dtype=torch.bfloat16
        )
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
    
    def generate_role_vectors(self, roles: List[str], strategy: str = "individual"):
        """ç”¢ç”Ÿå¤šè§’è‰²å‘é‡"""
        
        print(f"ğŸ“Š ä½¿ç”¨ç­–ç•¥: {strategy}")
        
        if strategy == "individual":
            return self._generate_individual_vectors(roles)
        elif strategy == "vs_baseline":
            return self._generate_baseline_vectors(roles)
        elif strategy == "pairwise":
            return self._generate_pairwise_vectors(roles)
        else:
            raise ValueError(f"æœªçŸ¥ç­–ç•¥: {strategy}")
    
    def _generate_individual_vectors(self, roles: List[str]) -> Dict[str, torch.Tensor]:
        """ç”¢ç”Ÿç¨ç«‹è§’è‰²å‘é‡ï¼ˆè§’è‰²ç‰¹å¾µ vs ä¸­æ€§åŸºæº–ï¼‰"""
        vectors = {}
        
        for role_name in roles:
            print(f"ğŸ­ è¨ˆç®— {role_name} å‘é‡...")
            
            pos_path = f"eval_persona_extract/{self.model_short_name}/{role_name}_pos_instruct.csv"
            neg_path = f"eval_persona_extract/{self.model_short_name}/{role_name}_neutral_instruct.csv"
            
            if not (os.path.exists(pos_path) and os.path.exists(neg_path)):
                print(f"âš ï¸  æ‰¾ä¸åˆ° {role_name} çš„è³‡æ–™æª”æ¡ˆï¼Œè·³é...")
                continue
            
            try:
                # æª¢æŸ¥è³‡æ–™å“è³ª
                quality_info = self._check_data_quality_adaptive(pos_path, neg_path, role_name)
                
                if not quality_info['is_sufficient']:
                    print(f"âš ï¸  {role_name} è³‡æ–™å“è³ªä¸è¶³ï¼Œè·³é...")
                    continue
                
                # ä½¿ç”¨é©æ‡‰æ€§é–¾å€¼è¨ˆç®—å‘é‡
                vector = self._compute_single_vector_adaptive(
                    pos_path, neg_path, role_name, quality_info
                )
                
                if vector is not None:
                    vectors[role_name] = vector
                    
                    # å„²å­˜å€‹åˆ¥å‘é‡
                    vector_path = os.path.join(self.save_dir, f"{role_name}_response_avg_diff.pt")
                    torch.save(vector, vector_path)
                    print(f"ğŸ’¾ å„²å­˜: {vector_path}")
                    print(f"ğŸ“ å‘é‡å½¢ç‹€: {vector.shape}")
                else:
                    print(f"âŒ {role_name} å‘é‡è¨ˆç®—å¤±æ•—")
                    
            except Exception as e:
                print(f"âŒ è™•ç† {role_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        return vectors
    
    def _check_data_quality_adaptive(self, pos_path: str, neg_path: str, role_name: str) -> Dict:
        """é©æ‡‰æ€§è³‡æ–™å“è³ªæª¢æŸ¥"""
        try:
            pos_data = pd.read_csv(pos_path)
            neg_data = pd.read_csv(neg_path)
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            if role_name not in pos_data.columns or role_name not in neg_data.columns:
                print(f"   âŒ æ‰¾ä¸åˆ° {role_name} æ¬„ä½")
                return {'is_sufficient': False}
            
            # åˆ†æåˆ†æ•¸åˆ†ä½ˆ
            pos_scores = pos_data[role_name].dropna()
            neg_scores = neg_data[role_name].dropna()
            
            print(f"   ğŸ“Š åˆ†æ•¸åˆ†ä½ˆ:")
            print(f"      æ­£é¢è³‡æ–™: å¹³å‡ {pos_scores.mean():.2f}, ç¯„åœ {pos_scores.min():.2f}-{pos_scores.max():.2f}")
            print(f"      è² é¢è³‡æ–™: å¹³å‡ {neg_scores.mean():.2f}, ç¯„åœ {neg_scores.min():.2f}-{neg_scores.max():.2f}")
            
            # è¨ˆç®—é©æ‡‰æ€§é–¾å€¼
            pos_median = pos_scores.median()
            neg_median = neg_scores.median()
            
            # å¦‚æœè² é¢è³‡æ–™åˆ†æ•¸åé«˜ï¼Œä½¿ç”¨ç›¸å°é–¾å€¼
            if neg_median > 70:
                pos_threshold = max(pos_median, 80)  # æ­£é¢è¦æ±‚æ›´é«˜
                neg_threshold = neg_median  # è² é¢ä½¿ç”¨ä¸­ä½æ•¸
            else:
                pos_threshold = max(50, pos_median)
                neg_threshold = min(50, neg_median)
            
            print(f"   ğŸ¯ é©æ‡‰æ€§é–¾å€¼: æ­£é¢ >= {pos_threshold:.1f}, è² é¢ <= {neg_threshold:.1f}")
            
            # ç¯©é¸é«˜å“è³ªæ¨£æœ¬
            pos_quality = pos_data[
                (pos_data[role_name] >= pos_threshold) & 
                (pos_data["coherence"] >= 50)
            ]
            
            neg_quality = neg_data[
                (neg_data[role_name] <= neg_threshold) & 
                (neg_data["coherence"] >= 50)
            ]
            
            print(f"   ğŸ“Š é«˜å“è³ªæ¨£æœ¬: æ­£é¢ {len(pos_quality)}, è² é¢ {len(neg_quality)}")
            
            # æ”¾å¯¬è¦æ±‚ï¼šåªè¦æœ‰åˆç†çš„æ¨£æœ¬æ•¸é‡å³å¯
            is_sufficient = len(pos_quality) >= 3 and len(neg_quality) >= 3
            
            return {
                'is_sufficient': is_sufficient,
                'pos_threshold': pos_threshold,
                'neg_threshold': neg_threshold,
                'pos_count': len(pos_quality),
                'neg_count': len(neg_quality)
            }
            
        except Exception as e:
            print(f"   âŒ æª¢æŸ¥è³‡æ–™å“è³ªæ™‚å‡ºéŒ¯: {e}")
            return {'is_sufficient': False}
    
    def _compute_single_vector_adaptive(self, pos_path: str, neg_path: str, 
                                       trait: str, quality_info: Dict) -> torch.Tensor:
        """ä½¿ç”¨é©æ‡‰æ€§é–¾å€¼è¨ˆç®—å‘é‡"""
        try:
            # ä½¿ç”¨é©æ‡‰æ€§é–¾å€¼
            pos_threshold = quality_info.get('pos_threshold', 70)
            neg_threshold = quality_info.get('neg_threshold', 30)
            
            print(f"   ğŸ¯ ä½¿ç”¨é–¾å€¼: æ­£é¢ >= {pos_threshold:.1f}, è² é¢ <= {neg_threshold:.1f}")
            
            # æ‰‹å‹•ç¯©é¸è³‡æ–™
            pos_data = pd.read_csv(pos_path)
            neg_data = pd.read_csv(neg_path)
            
            # ç¯©é¸é«˜å“è³ªæ­£é¢æ¨£æœ¬
            pos_effective = pos_data[
                (pos_data[trait] >= pos_threshold) & 
                (pos_data["coherence"] >= 50)
            ]
            
            # ç¯©é¸é«˜å“è³ªè² é¢æ¨£æœ¬
            neg_effective = neg_data[
                (neg_data[trait] <= neg_threshold) & 
                (neg_data["coherence"] >= 50)
            ]
            
            print(f"   ğŸ“Š ç¯©é¸çµæœ: æ­£é¢ {len(pos_effective)}, è² é¢ {len(neg_effective)}")
            
            if len(pos_effective) == 0 or len(neg_effective) == 0:
                print(f"   âš ï¸  ç¯©é¸å¾Œè³‡æ–™ä¸è¶³")
                return None
            
            # æå–æç¤ºè©å’Œå›æ‡‰
            pos_prompts = pos_effective['prompt'].tolist()
            pos_responses = pos_effective['answer'].tolist()
            neg_prompts = neg_effective['prompt'].tolist()
            neg_responses = neg_effective['answer'].tolist()
            
            # é™åˆ¶è³‡æ–™æ•¸é‡é¿å…è¨˜æ†¶é«”å•é¡Œ
            max_samples = 20
            if len(pos_prompts) > max_samples:
                pos_prompts = pos_prompts[:max_samples]
                pos_responses = pos_responses[:max_samples]
            if len(neg_prompts) > max_samples:
                neg_prompts = neg_prompts[:max_samples]
                neg_responses = neg_responses[:max_samples]
            
            # è¨ˆç®—é©ç•¶çš„æ‰¹æ¬¡å¤§å°
            batch_size = min(2, len(pos_prompts), len(neg_prompts))
            
            print(f"   ğŸ§  æå–æ­£é¢æ¿€æ´» (æ¨£æœ¬: {len(pos_prompts)}, æ‰¹æ¬¡: {batch_size})...")
            _, _, pos_activations = get_hidden_p_and_r_batched(
                self.model, self.tokenizer, 
                pos_prompts, pos_responses,
                batch_size=batch_size
            )
            
            print(f"   ğŸ§  æå–è² é¢æ¿€æ´» (æ¨£æœ¬: {len(neg_prompts)}, æ‰¹æ¬¡: {batch_size})...")
            _, _, neg_activations = get_hidden_p_and_r_batched(
                self.model, self.tokenizer,
                neg_prompts, neg_responses, 
                batch_size=batch_size
            )
            
            # è¨ˆç®—å·®ç•°å‘é‡
            print(f"   ğŸ¯ è¨ˆç®—å‘é‡å·®ç•°...")
            response_avg_diff = torch.stack([
                pos_activations[l].mean(0).float() - 
                neg_activations[l].mean(0).float() 
                for l in range(len(pos_activations))
            ], dim=0)
            
            return response_avg_diff
            
        except Exception as e:
            print(f"   âŒ å‘é‡è¨ˆç®—éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _generate_baseline_vectors(self, roles: List[str], baseline_role: str = None) -> Dict[str, torch.Tensor]:
        """ç”¢ç”Ÿç›¸å°æ–¼åŸºæº–è§’è‰²çš„å‘é‡"""
        print("ğŸ”„ ç”¢ç”ŸåŸºæº–å°æ¯”å‘é‡...")
        return {}
    
    def _generate_pairwise_vectors(self, roles: List[str]) -> Dict[str, torch.Tensor]:
        """ç”¢ç”Ÿè§’è‰²å°æ¯”å‘é‡"""
        print("ğŸ”„ ç”¢ç”Ÿè§’è‰²å°æ¯”å‘é‡...")
        return {}

# ä½¿ç”¨ç¯„ä¾‹
def main():
    
    # generator = MultiRoleVectorGenerator(
    #     model_name="Qwen/Qwen2.5-7B-Instruct",
    #     save_dir="persona_vectors/Qwen2.5-7B-Instruct/multi_role/"
    # )

    # # TODO: change to Llama-3.1-8B-Instruct
    # generator = MultiRoleVectorGenerator(
    #     model_name="meta-llama/Llama-3.1-8B-Instruct",
    #     save_dir="persona_vectors/Llama-3.1-8B-Instruct/multi_role/"
    # )

    generator = MultiRoleVectorGenerator(
        model_name="google/gemma-3-4b-it",
        save_dir="persona_vectors/gemma-3-4b-it/multi_role/"
    )
    
    roles = [
        "creative_professional",
        # "analytical_thinker", 
        # "empathetic_counselor",
        # "academic_researcher",
        # "customer_user",
        # "digital_nomad",
        "environmentalist",
        "futurist",
        # "industry_insider",
        # "social_entrepreneur",
        # "startup_founder",
        # "visionary_millionaire"
    ]
    
    for role in roles:
        print(f"ğŸ¯ å…ˆæ¸¬è©¦ {role} çš„è³‡æ–™ç”¢ç”Ÿ...")
        try:
            generator.generate_role_vectors([role], strategy="individual")
            print(f"âœ… {role} å‘é‡ç”¢ç”ŸæˆåŠŸï¼")
        except Exception as e:
            print(f"âŒ {role} å‘é‡è¨ˆç®—å¤±æ•—: {e}")
        print("--------------------------------------------------")

    # å…ˆæ¸¬è©¦ä¸€å€‹è§’è‰²
    # print("ğŸ¯ ç”¢ç”Ÿç¨ç«‹è§’è‰²å‘é‡...")
    # individual_vectors = generator.generate_role_vectors(roles, "individual")
    
    print("âœ… æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    main()