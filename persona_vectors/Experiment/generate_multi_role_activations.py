# import subprocess
# import os
# from typing import List, Dict

# class MultiRoleActivationGenerator:
#     """å¤šè§’è‰²æ¿€æ´»è³‡æ–™ç”¢ç”Ÿå™¨"""
    
#     def __init__(self, model_name: str = "Qwen/Qwen2.5-7B-Instruct"):
#         self.model_name = model_name
#         self.model_short_name = model_name.split('/')[-1]
    
#     def generate_role_activations(self, roles: List[str], gpu_id: int = 0):
#         """ç‚ºå¤šå€‹è§’è‰²ç”¢ç”Ÿæ¿€æ´»è³‡æ–™"""
        
#         for role_name in roles:
#             print(f"ğŸ­ ç”¢ç”Ÿ {role_name} çš„æ¿€æ´»è³‡æ–™...")
            
#             # ç”¢ç”Ÿè§’è‰²ç‰¹å¾µè³‡æ–™ï¼ˆç›¸ç•¶æ–¼ posï¼‰
#             self._run_eval_persona(
#                 role_name=role_name,
#                 persona_type="pos",
#                 assistant_name=role_name,
#                 gpu_id=gpu_id
#             )
            
#             # ç”¢ç”Ÿä¸­æ€§åŸºæº–è³‡æ–™ï¼ˆç›¸ç•¶æ–¼ negï¼‰
#             self._run_eval_persona(
#                 role_name=role_name,
#                 persona_type="neg", 
#                 assistant_name="helpful",
#                 gpu_id=gpu_id,
#                 output_suffix="neutral"
#             )
    
#     def _run_eval_persona(self, role_name: str, persona_type: str, 
#                          assistant_name: str, gpu_id: int, output_suffix: str = None):
#         """åŸ·è¡Œå–®ä¸€è§’è‰²çš„è©•ä¼°"""
        
#         if output_suffix:
#             output_path = f"eval_persona_extract/{self.model_short_name}/{role_name}_{output_suffix}_instruct.csv"
#         else:
#             output_path = f"eval_persona_extract/{self.model_short_name}/{role_name}_{persona_type}_instruct.csv"
        
#         # å»ºç«‹è¼¸å‡ºç›®éŒ„
#         os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
#         cmd = [
#             "python", "-m", "eval.eval_persona",
#             "--model", self.model_name,
#             "--trait", role_name,
#             "--output_path", output_path,
#             "--persona_instruction_type", persona_type,
#             "--assistant_name", assistant_name,
#             "--judge_model", "gpt-4o-mini",
#             "--version", "extract"
#         ]
        
#         env = os.environ.copy()
#         env["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
        
#         try:
#             subprocess.run(cmd, env=env, check=True)
#             print(f"âœ… {role_name} ({persona_type}) è³‡æ–™ç”¢ç”Ÿå®Œæˆ")
#         except subprocess.CalledProcessError as e:
#             print(f"âŒ {role_name} ({persona_type}) è³‡æ–™ç”¢ç”Ÿå¤±æ•—: {e}")

# # ä½¿ç”¨ç¯„ä¾‹
# def main():
#     generator = MultiRoleActivationGenerator()
    
#     roles = [
#         "creative_professional",
#         # "analytical_thinker", 
#         # "empathetic_counselor"
#     ]
    
#     generator.generate_role_activations(roles, gpu_id=0)

# if __name__ == "__main__":
#     main()

import subprocess
import os
from typing import List, Dict

class MultiRoleActivationGenerator:
    """å¤šè§’è‰²æ¿€æ´»è³‡æ–™ç”¢ç”Ÿå™¨"""
    
    def __init__(self, model_name: str = "Qwen/Qwen2.5-7B-Instruct"):
        self.model_name = model_name
        self.model_short_name = model_name.split('/')[-1]
    
    def generate_role_activations(self, roles: List[str], gpu_id: int = 0, force_regenerate: bool = False):
        """ç‚ºå¤šå€‹è§’è‰²ç”¢ç”Ÿæ¿€æ´»è³‡æ–™"""
        
        for role_name in roles:
            print(f"ğŸ­ ç”¢ç”Ÿ {role_name} çš„æ¿€æ´»è³‡æ–™...")
            
            # ç”¢ç”Ÿè§’è‰²ç‰¹å¾µè³‡æ–™ï¼ˆç›¸ç•¶æ–¼ posï¼‰
            self._run_eval_persona(
                role_name=role_name,
                persona_type="pos",
                assistant_name=role_name,
                gpu_id=gpu_id,
                force_regenerate=force_regenerate
            )
            
            # ç”¢ç”Ÿä¸­æ€§åŸºæº–è³‡æ–™ï¼ˆç›¸ç•¶æ–¼ negï¼‰
            self._run_eval_persona(
                role_name=role_name,
                persona_type="neg", 
                assistant_name="helpful",
                gpu_id=gpu_id,
                output_suffix="neutral",
                force_regenerate=force_regenerate
            )
    
    def _run_eval_persona(self, role_name: str, persona_type: str, 
                         assistant_name: str, gpu_id: int, output_suffix: str = None,
                         force_regenerate: bool = False):
        """åŸ·è¡Œå–®ä¸€è§’è‰²çš„è©•ä¼°"""
        
        if output_suffix:
            output_path = f"eval_persona_extract/{self.model_short_name}/{role_name}_{output_suffix}_instruct.csv"
        else:
            output_path = f"eval_persona_extract/{self.model_short_name}/{role_name}_{persona_type}_instruct.csv"
        
        # å¦‚æœå¼·åˆ¶é‡æ–°ç”¢ç”Ÿï¼Œå…ˆåˆªé™¤èˆŠæª”æ¡ˆ
        if force_regenerate and os.path.exists(output_path):
            print(f"ğŸ—‘ï¸  åˆªé™¤èˆŠæª”æ¡ˆ: {output_path}")
            os.remove(output_path)
        
        # å»ºç«‹è¼¸å‡ºç›®éŒ„
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        cmd = [
            "python", "-m", "eval.eval_persona",
            "--model", self.model_name,
            "--trait", role_name,
            "--output_path", output_path,
            "--persona_instruction_type", persona_type,
            "--assistant_name", assistant_name,
            "--judge_model", "gpt-4o-mini",
            "--version", "extract"
        ]
        
        env = os.environ.copy()
        env["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
        
        try:
            subprocess.run(cmd, env=env, check=True)
            print(f"âœ… {role_name} ({persona_type}) è³‡æ–™ç”¢ç”Ÿå®Œæˆ")
            
            # æª¢æŸ¥ç”¢ç”Ÿçš„è³‡æ–™å“è³ª
            self._check_data_quality(output_path, role_name)
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ {role_name} ({persona_type}) è³‡æ–™ç”¢ç”Ÿå¤±æ•—: {e}")
    
    def _check_data_quality(self, output_path: str, role_name: str):
        """æª¢æŸ¥ç”¢ç”Ÿçš„è³‡æ–™å“è³ª"""
        try:
            import pandas as pd
            data = pd.read_csv(output_path)
            
            if role_name in data.columns:
                valid_scores = data[role_name].dropna()
                if len(valid_scores) > 0:
                    print(f"   ğŸ“Š {role_name} åˆ†æ•¸: å¹³å‡ {valid_scores.mean():.2f}, ç¯„åœ {valid_scores.min():.2f}-{valid_scores.max():.2f}")
                else:
                    print(f"   âš ï¸  {role_name} æ‰€æœ‰åˆ†æ•¸éƒ½æ˜¯ NaN")
            else:
                print(f"   âš ï¸  æ‰¾ä¸åˆ° {role_name} æ¬„ä½ï¼Œå¯ç”¨æ¬„ä½: {data.columns.tolist()}")
                
        except Exception as e:
            print(f"   âŒ æª¢æŸ¥è³‡æ–™å“è³ªæ™‚å‡ºéŒ¯: {e}")

# ä½¿ç”¨ç¯„ä¾‹
def main():
    generator = MultiRoleActivationGenerator()
    
    roles = [
        "creative_professional",
        "analytical_thinker", 
        "empathetic_counselor"
    ]
    
    # å¼·åˆ¶é‡æ–°ç”¢ç”Ÿä»¥è§£æ±º NaN å•é¡Œ
    generator.generate_role_activations(roles, gpu_id=0, force_regenerate=True)

if __name__ == "__main__":
    main()