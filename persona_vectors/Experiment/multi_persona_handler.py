import torch
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional

class MultiPersonaHandler:
    """è™•ç†å¤šé‡ Persona å‘é‡çš„é¡åˆ¥"""
    
    def __init__(self, vector_paths: List[str], fusion_method: str = "weighted_average"):
        self.vector_paths = vector_paths
        self.fusion_method = fusion_method
        self.personas = {}
        self.fused_vector = None
        
        # è¼‰å…¥æ‰€æœ‰ persona å‘é‡
        self.load_all_personas()
        
    def load_all_personas(self):
        """è¼‰å…¥æ‰€æœ‰ persona å‘é‡æª”æ¡ˆ"""
        for i, path in enumerate(self.vector_paths):
            persona_name = f"persona_{i+1}"
            print(f"ğŸ“ è¼‰å…¥ {persona_name}: {path}")
            
            vector = torch.load(path, map_location='cpu')
            self.personas[persona_name] = vector
            print(f"âœ… {persona_name} å‘é‡ç¶­åº¦: {vector.shape}")
    
    def fuse_vectors(self, weights: Optional[List[float]] = None) -> torch.Tensor:
        """èåˆå¤šå€‹ persona å‘é‡"""
        if not self.personas:
            raise ValueError("æ²’æœ‰å¯ç”¨çš„ persona å‘é‡")
        
        vectors = list(self.personas.values())
        
        if self.fusion_method == "weighted_average":
            return self._weighted_average_fusion(vectors, weights)
        elif self.fusion_method == "concatenate":
            return self._concatenate_fusion(vectors)
        elif self.fusion_method == "attention":
            return self._attention_fusion(vectors)
        elif self.fusion_method == "dynamic":
            return self._dynamic_fusion(vectors)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„èåˆæ–¹æ³•: {self.fusion_method}")
    
    def _weighted_average_fusion(self, vectors: List[torch.Tensor], weights: Optional[List[float]] = None) -> torch.Tensor:
        """åŠ æ¬Šå¹³å‡èåˆ"""
        if weights is None:
            weights = [1.0 / len(vectors)] * len(vectors)
        
        if len(weights) != len(vectors):
            raise ValueError("æ¬Šé‡æ•¸é‡å¿…é ˆèˆ‡å‘é‡æ•¸é‡ç›¸åŒ")
        
        fused = torch.zeros_like(vectors[0])
        for vector, weight in zip(vectors, weights):
            fused += weight * vector
        
        return fused
    
    def _concatenate_fusion(self, vectors: List[torch.Tensor]) -> torch.Tensor:
        """ä¸²æ¥èåˆ"""
        return torch.cat(vectors, dim=-1)
    
    def _attention_fusion(self, vectors: List[torch.Tensor]) -> torch.Tensor:
        """æ³¨æ„åŠ›æ©Ÿåˆ¶èåˆ"""
        # ç°¡åŒ–çš„æ³¨æ„åŠ›æ©Ÿåˆ¶
        stacked = torch.stack(vectors, dim=0)  # [num_vectors, ...]
        
        # è¨ˆç®—æ³¨æ„åŠ›æ¬Šé‡
        attention_scores = torch.softmax(torch.randn(len(vectors)), dim=0)
        
        # æ‡‰ç”¨æ³¨æ„åŠ›æ¬Šé‡
        fused = torch.sum(attention_scores.unsqueeze(-1) * stacked, dim=0)
        return fused
    
    def _dynamic_fusion(self, vectors: List[torch.Tensor]) -> torch.Tensor:
        """å‹•æ…‹èåˆï¼ˆæ ¹æ“šè¼¸å…¥èª¿æ•´ï¼‰"""
        # é€™è£¡å¯ä»¥æ ¹æ“šç•¶å‰è¼¸å…¥å‹•æ…‹èª¿æ•´èåˆç­–ç•¥
        # æš«æ™‚ä½¿ç”¨ç­‰æ¬Šé‡å¹³å‡
        return self._weighted_average_fusion(vectors)

class MultiPersonaChatbot:
    """æ”¯æ´å¤šé‡ Persona çš„èŠå¤©æ©Ÿå™¨äºº"""
    
    def __init__(self, model_name: str, vector_paths: List[str], 
                 layer_idx: int = 20, steering_coef: float = 2.0,
                 fusion_method: str = "weighted_average"):
        
        # å°å…¥æœ¬åœ°çš„ PersonaChatbot
        import sys
        from pathlib import Path
        sys.path.append(str(Path(__file__).parent))
        
        from interactive_chat import PersonaChatbot
        
        # è™•ç†æª”æ¡ˆè·¯å¾‘ï¼Œè‡ªå‹•æ·»åŠ å®Œæ•´è·¯å¾‘
        processed_paths = []
        for path in vector_paths:
            if not Path(path).exists():
                # å˜—è©¦åœ¨ persona_vectors/Qwen2.5-7B-Instruct/multi_role/ ç›®éŒ„ä¸­å°‹æ‰¾
                # full_path = Path(__file__).parent.parent / "persona_vectors" / "Qwen2.5-7B-Instruct" / "multi_role" / path
                full_path = Path(__file__).parent.parent / "persona_vectors" / "Llama-3.1-8B-Instruct" / "multi_role" / path
                if full_path.exists():
                    processed_paths.append(str(full_path))
                    print(f"ğŸ“ æ‰¾åˆ°å‘é‡æª”æ¡ˆ: {full_path}")
                else:
                    raise FileNotFoundError(f"æ‰¾ä¸åˆ°å‘é‡æª”æ¡ˆ: {path}")
            else:
                processed_paths.append(path)
        
        self.base_chatbot = PersonaChatbot(model_name, processed_paths[0], layer_idx, steering_coef)
        self.persona_handler = MultiPersonaHandler(processed_paths, fusion_method)
        self.current_weights = [1.0/len(vector_paths)] * len(vector_paths)
        
        # ä½¿ç”¨èåˆå¾Œçš„å‘é‡
        self.update_persona_weights(self.current_weights)
    
    def update_persona_weights(self, weights: List[float]):
        """æ›´æ–° persona æ¬Šé‡ä¸¦é‡æ–°èåˆå‘é‡"""
        self.current_weights = weights
        fused_vector = self.persona_handler.fuse_vectors(weights)
        
        # æ›´æ–°åŸºç¤èŠå¤©æ©Ÿå™¨äººçš„ persona å‘é‡
        self.base_chatbot.persona_vector = fused_vector
        print(f"ğŸ­ æ›´æ–° persona æ¬Šé‡: {weights}")
    
    def set_persona_mode(self, mode: str):
        """è¨­å®šç‰¹å®šçš„ persona æ¨¡å¼"""
        num_personas = len(self.persona_handler.personas)
        
        if mode == "balanced":
            # å¹³è¡¡æ¨¡å¼ï¼šæ‰€æœ‰ persona ç­‰æ¬Šé‡
            weights = [1.0/num_personas] * num_personas
        elif mode == "persona_1":
            # ä¸»è¦ä½¿ç”¨ç¬¬ä¸€å€‹ persona
            weights = [0.8, 0.1, 0.1][:num_personas]
        elif mode == "persona_2":
            # ä¸»è¦ä½¿ç”¨ç¬¬äºŒå€‹ persona
            weights = [0.1, 0.8, 0.1][:num_personas]
        elif mode == "persona_3":
            # ä¸»è¦ä½¿ç”¨ç¬¬ä¸‰å€‹ persona
            weights = [0.1, 0.1, 0.8][:num_personas]
        elif mode == "creative":
            # å‰µæ„æ¨¡å¼ï¼šå‹•æ…‹æ¬Šé‡
            weights = [0.4, 0.3, 0.3][:num_personas]
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å¼: {mode}")
        
        self.update_persona_weights(weights)
    
    def generate_response(self, user_input: str, max_tokens: int = 16384) -> str:
        """ç”¢ç”Ÿå›æ‡‰"""
        return self.base_chatbot.generate_response(user_input, max_tokens)
    
    def reset_conversation(self):
        """é‡è¨­å°è©±æ­·å²"""
        self.base_chatbot.conversation_history = []